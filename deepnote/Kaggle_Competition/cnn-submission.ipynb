{
  "cells": [
    {
      "cell_type": "code",
      "source": "# import the libraries\nimport numpy as np\nimport dask.dataframe as dd\nfrom dask.diagnostics import ProgressBar\nfrom itertools import product\nimport matplotlib.pyplot as plt\n# from fitter import Fitter, get_common_distributions, get_distributions",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-12-17T00:08:33.213346Z",
          "iopub.status.idle": "2023-12-17T00:08:37.989712Z",
          "iopub.execute_input": "2023-12-17T00:08:33.213662Z",
          "shell.execute_reply": "2023-12-17T00:08:37.988819Z",
          "shell.execute_reply.started": "2023-12-17T00:08:33.213636Z"
        },
        "cell_id": "cedb139c0f064dcd8ffff474a471a00e",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 2,
      "block_group": "b88a1db7bffa49d881744a9811dc3f5f"
    },
    {
      "cell_type": "code",
      "source": "# import, shuffle, and see the data\nddf = dd.read_csv('/kaggle/input/rna-data/train_data_p_unp.csv')\nshfl_ddf = ddf.sample(frac = 1, random_state = 42)\nshfl_ddf.head()",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-12-17T00:08:37.991604Z",
          "iopub.status.idle": "2023-12-17T00:08:41.561863Z",
          "iopub.execute_input": "2023-12-17T00:08:37.992380Z",
          "shell.execute_reply": "2023-12-17T00:08:41.560699Z",
          "shell.execute_reply.started": "2023-12-17T00:08:37.992347Z"
        },
        "cell_id": "76e402ba586247fa8ef6b7c8e5d5ccc9",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "       Unnamed: 0   sequence_id  \\\n5420         5420  ab587c2d24eb   \n16450        4202  309b8583b119   \n4544         4544  4ed1f0557392   \n17837        5589  93235436cac4   \n14752        2504  969913b8537c   \n\n                                                sequence experiment_type  \\\n5420   GGGAACGACUCGAGUAGAGUCGAAAAGGCCUAGGGCGGGCGGGAAU...         DMS_MaP   \n16450  GGGAACGACUCGAGUAGAGUCGAAAAAAGACCUACAUACAUUGUAU...         2A3_MaP   \n4544   GGGAACGACUCGAGUAGAGUCGAAAAGCUGAUUGCCUGGCGGCUAC...         2A3_MaP   \n17837  GGGAACGACUCGAGUAGAGUCGAAAAAUUAUUAGAAGGGGGUAAUG...         2A3_MaP   \n14752  GGGAACGACUCGAGUAGAGUCGAAAACAUGGUCACCACUGUUGGCG...         2A3_MaP   \n\n                                            dataset_name  reads  \\\n5420      DasLabBigLib_OneMil_OpenKnot_Round_2_train_DMS      0   \n16450  DasLabBigLib_OneMil_Coronavirus_genomes_SARS_r...    162   \n4544      DasLabBigLib_OneMil_OpenKnot_Round_2_train_2A3    702   \n17837     DasLabBigLib_OneMil_OpenKnot_Round_2_train_2A3      3   \n14752  DasLabBigLib_OneMil_Coronavirus_genomes_SARS_r...    504   \n\n       signal_to_noise  SN_filter  reactivity_0001  reactivity_0002  ...  \\\n5420             0.000          0              NaN              NaN  ...   \n16450            0.538          0              NaN              NaN  ...   \n4544             1.553          1              NaN              NaN  ...   \n17837            0.000          0              NaN              NaN  ...   \n14752            0.910          0              NaN              NaN  ...   \n\n       p_unp_197  p_unp_198  p_unp_199  p_unp_200  p_unp_201  p_unp_202  \\\n5420         1.0        1.0        1.0        1.0        1.0        1.0   \n16450        1.0        1.0        1.0        1.0        1.0        1.0   \n4544         1.0        1.0        1.0        1.0        1.0        1.0   \n17837        1.0        1.0        1.0        1.0        1.0        1.0   \n14752        1.0        1.0        1.0        1.0        1.0        1.0   \n\n       p_unp_203  p_unp_204  p_unp_205  p_unp_206  \n5420         1.0        1.0        1.0        1.0  \n16450        1.0        1.0        1.0        1.0  \n4544         1.0        1.0        1.0        1.0  \n17837        1.0        1.0        1.0        1.0  \n14752        1.0        1.0        1.0        1.0  \n\n[5 rows x 626 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>sequence_id</th>\n      <th>sequence</th>\n      <th>experiment_type</th>\n      <th>dataset_name</th>\n      <th>reads</th>\n      <th>signal_to_noise</th>\n      <th>SN_filter</th>\n      <th>reactivity_0001</th>\n      <th>reactivity_0002</th>\n      <th>...</th>\n      <th>p_unp_197</th>\n      <th>p_unp_198</th>\n      <th>p_unp_199</th>\n      <th>p_unp_200</th>\n      <th>p_unp_201</th>\n      <th>p_unp_202</th>\n      <th>p_unp_203</th>\n      <th>p_unp_204</th>\n      <th>p_unp_205</th>\n      <th>p_unp_206</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5420</th>\n      <td>5420</td>\n      <td>ab587c2d24eb</td>\n      <td>GGGAACGACUCGAGUAGAGUCGAAAAGGCCUAGGGCGGGCGGGAAU...</td>\n      <td>DMS_MaP</td>\n      <td>DasLabBigLib_OneMil_OpenKnot_Round_2_train_DMS</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>16450</th>\n      <td>4202</td>\n      <td>309b8583b119</td>\n      <td>GGGAACGACUCGAGUAGAGUCGAAAAAAGACCUACAUACAUUGUAU...</td>\n      <td>2A3_MaP</td>\n      <td>DasLabBigLib_OneMil_Coronavirus_genomes_SARS_r...</td>\n      <td>162</td>\n      <td>0.538</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4544</th>\n      <td>4544</td>\n      <td>4ed1f0557392</td>\n      <td>GGGAACGACUCGAGUAGAGUCGAAAAGCUGAUUGCCUGGCGGCUAC...</td>\n      <td>2A3_MaP</td>\n      <td>DasLabBigLib_OneMil_OpenKnot_Round_2_train_2A3</td>\n      <td>702</td>\n      <td>1.553</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>17837</th>\n      <td>5589</td>\n      <td>93235436cac4</td>\n      <td>GGGAACGACUCGAGUAGAGUCGAAAAAUUAUUAGAAGGGGGUAAUG...</td>\n      <td>2A3_MaP</td>\n      <td>DasLabBigLib_OneMil_OpenKnot_Round_2_train_2A3</td>\n      <td>3</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>14752</th>\n      <td>2504</td>\n      <td>969913b8537c</td>\n      <td>GGGAACGACUCGAGUAGAGUCGAAAACAUGGUCACCACUGUUGGCG...</td>\n      <td>2A3_MaP</td>\n      <td>DasLabBigLib_OneMil_Coronavirus_genomes_SARS_r...</td>\n      <td>504</td>\n      <td>0.910</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 626 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "block_group": "7e6310daeb894197940a68b51f438755"
    },
    {
      "cell_type": "code",
      "source": "dms_ddf = ddf.loc[ddf['experiment_type'] == \"DMS_MaP\"]\ntwoa3_ddf = ddf.loc[ddf['experiment_type'] == \"2A3_MaP\"]\ndms_ddf.head()",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-12-17T00:08:41.563082Z",
          "iopub.status.idle": "2023-12-17T00:08:43.611301Z",
          "iopub.execute_input": "2023-12-17T00:08:41.563415Z",
          "shell.execute_reply": "2023-12-17T00:08:43.610369Z",
          "shell.execute_reply.started": "2023-12-17T00:08:41.563382Z"
        },
        "cell_id": "231d47ee49c14aa8af1c9ba4608d7c23",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "execution_count": 4,
          "output_type": "execute_result",
          "data": {
            "text/plain": "    Unnamed: 0   sequence_id  \\\n14          14  70cdf97f6392   \n15          15  bad76a72215c   \n16          16  f037cc8df765   \n17          17  e63fe5ebb069   \n18          18  a4a9f51c982e   \n\n                                             sequence experiment_type  \\\n14  GGGAACGACUCGAGUAGAGUCGAAAACCUGGAGGAGGAUGGAACAC...         DMS_MaP   \n15  GGGAACGACUCGAGUAGAGUCGAAAAUAAAUUCAGCGGUAAUUCCU...         DMS_MaP   \n16  GGGAACGACUCGAGUAGAGUCGAAAAUACCGAGAAAGAUCCUCGGU...         DMS_MaP   \n17  GGGAACGACUCGAGUAGAGUCGAAAACGGGCAAACUAGAAAAGCCC...         DMS_MaP   \n18  GGGAACGACUCGAGUAGAGUCGAAAAGGGUCCAGCCUGGAAAGGCU...         DMS_MaP   \n\n                   dataset_name   reads  signal_to_noise  SN_filter  \\\n14  PK50_AltChemMap_NovaSeq_DMS  103505           35.334          1   \n15  PK50_AltChemMap_NovaSeq_DMS   12725            8.874          1   \n16  PK50_AltChemMap_NovaSeq_DMS   60600           24.826          1   \n17  PK50_AltChemMap_NovaSeq_DMS   16034           13.426          1   \n18  PK50_AltChemMap_NovaSeq_DMS  306828           41.648          1   \n\n    reactivity_0001  reactivity_0002  ...  p_unp_197  p_unp_198  p_unp_199  \\\n14              NaN              NaN  ...        1.0        1.0        1.0   \n15              NaN              NaN  ...        1.0        1.0        1.0   \n16              NaN              NaN  ...        1.0        1.0        1.0   \n17              NaN              NaN  ...        1.0        1.0        1.0   \n18              NaN              NaN  ...        1.0        1.0        1.0   \n\n    p_unp_200  p_unp_201  p_unp_202  p_unp_203  p_unp_204  p_unp_205  \\\n14        1.0        1.0        1.0        1.0        1.0        1.0   \n15        1.0        1.0        1.0        1.0        1.0        1.0   \n16        1.0        1.0        1.0        1.0        1.0        1.0   \n17        1.0        1.0        1.0        1.0        1.0        1.0   \n18        1.0        1.0        1.0        1.0        1.0        1.0   \n\n    p_unp_206  \n14        1.0  \n15        1.0  \n16        1.0  \n17        1.0  \n18        1.0  \n\n[5 rows x 626 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>sequence_id</th>\n      <th>sequence</th>\n      <th>experiment_type</th>\n      <th>dataset_name</th>\n      <th>reads</th>\n      <th>signal_to_noise</th>\n      <th>SN_filter</th>\n      <th>reactivity_0001</th>\n      <th>reactivity_0002</th>\n      <th>...</th>\n      <th>p_unp_197</th>\n      <th>p_unp_198</th>\n      <th>p_unp_199</th>\n      <th>p_unp_200</th>\n      <th>p_unp_201</th>\n      <th>p_unp_202</th>\n      <th>p_unp_203</th>\n      <th>p_unp_204</th>\n      <th>p_unp_205</th>\n      <th>p_unp_206</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>70cdf97f6392</td>\n      <td>GGGAACGACUCGAGUAGAGUCGAAAACCUGGAGGAGGAUGGAACAC...</td>\n      <td>DMS_MaP</td>\n      <td>PK50_AltChemMap_NovaSeq_DMS</td>\n      <td>103505</td>\n      <td>35.334</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>bad76a72215c</td>\n      <td>GGGAACGACUCGAGUAGAGUCGAAAAUAAAUUCAGCGGUAAUUCCU...</td>\n      <td>DMS_MaP</td>\n      <td>PK50_AltChemMap_NovaSeq_DMS</td>\n      <td>12725</td>\n      <td>8.874</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>16</td>\n      <td>f037cc8df765</td>\n      <td>GGGAACGACUCGAGUAGAGUCGAAAAUACCGAGAAAGAUCCUCGGU...</td>\n      <td>DMS_MaP</td>\n      <td>PK50_AltChemMap_NovaSeq_DMS</td>\n      <td>60600</td>\n      <td>24.826</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17</td>\n      <td>e63fe5ebb069</td>\n      <td>GGGAACGACUCGAGUAGAGUCGAAAACGGGCAAACUAGAAAAGCCC...</td>\n      <td>DMS_MaP</td>\n      <td>PK50_AltChemMap_NovaSeq_DMS</td>\n      <td>16034</td>\n      <td>13.426</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18</td>\n      <td>a4a9f51c982e</td>\n      <td>GGGAACGACUCGAGUAGAGUCGAAAAGGGUCCAGCCUGGAAAGGCU...</td>\n      <td>DMS_MaP</td>\n      <td>PK50_AltChemMap_NovaSeq_DMS</td>\n      <td>306828</td>\n      <td>41.648</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 626 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "block_group": "e9daa34480ec4af9a03bb0f946c466da"
    },
    {
      "cell_type": "code",
      "source": "# Modified version to account for probability of unpaired bases from secondary structure predictor. WITH padding.\nbases={'A':0, 'C':1, 'G':2, 'U':3 }\n\ndef one_hot(string, p_unpaired):\n\n    res = np.zeros((5, 457), # Now there are 5 rows in the input vector. 206 pairs vs 457 (kaggle test)\n                   dtype=np.float32)\n    res[4, :] = 1\n\n    for j in range(len(string)):\n        if string[j] in bases: # bases can be 'N' signifying missing: this corresponds to all 0 in the encoding\n            res[ bases[ string[j] ], j ]= 1.\n        res[4, j] = p_unpaired[j]\n\n    return res",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-12-17T00:08:43.614217Z",
          "iopub.status.idle": "2023-12-17T00:08:43.620807Z",
          "iopub.execute_input": "2023-12-17T00:08:43.614594Z",
          "shell.execute_reply": "2023-12-17T00:08:43.620003Z",
          "shell.execute_reply.started": "2023-12-17T00:08:43.614562Z"
        },
        "cell_id": "499f860178e449dfb2f4b64d05186db7",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 5,
      "block_group": "1064a291de7244d5a6272fd6ed690f5b"
    },
    {
      "cell_type": "code",
      "source": "# New padding function for inputs 206 -> 457 input CNN\n\ndef padding(react):\n  react_array = np.zeros(457, # 206 pairs vs 457 (kaggle test), pad everything else with zeros\n            dtype=np.float32)\n\n  react_array[0:len(react)] = react # Insert the known reactivity values (even if NaN). Everything else will be 0.\n\n  return react_array",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-12-17T00:08:43.621975Z",
          "iopub.status.idle": "2023-12-17T00:08:43.638303Z",
          "iopub.execute_input": "2023-12-17T00:08:43.622234Z",
          "shell.execute_reply": "2023-12-17T00:08:43.637548Z",
          "shell.execute_reply.started": "2023-12-17T00:08:43.622211Z"
        },
        "cell_id": "25c4b892f36d491383737990d14d99fe",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 6,
      "block_group": "db6babfd866647f98396515d66cbe5cc"
    },
    {
      "cell_type": "code",
      "source": "# For p_unpaired, with padding\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass BedPeaksDataset(torch.utils.data.IterableDataset):\n\n    def __init__(self, seq, p_unpaired, reactivities):\n        super(BedPeaksDataset, self).__init__()\n        self.seq = seq\n        self.reactivities = reactivities\n        self.p_unpaired = p_unpaired\n\n    def __iter__(self):\n        for i in range(len(self.seq)):\n            yield(one_hot(self.seq[i], self.p_unpaired[i]), padding(self.reactivities[i])) # positive example\n\n# train_dataset = BedPeaksDataset(seqs, reactivities)\n# train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=10, num_workers = 0)",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-12-17T00:08:43.639617Z",
          "iopub.status.idle": "2023-12-17T00:08:48.123459Z",
          "iopub.execute_input": "2023-12-17T00:08:43.640377Z",
          "shell.execute_reply": "2023-12-17T00:08:48.122631Z",
          "shell.execute_reply.started": "2023-12-17T00:08:43.640343Z"
        },
        "cell_id": "d023aabb5b324bbd854dc0eb37ae9556",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 7,
      "block_group": "03f2470d62d34bb8b763c0b296ad1377"
    },
    {
      "cell_type": "code",
      "source": "class CNN_1d(nn.Module):\n\n    def __init__(self,\n                 n_output_channels = 457,# Normally 206, vs 457\n                 filter_widths = [15, 15, 15],\n                 num_chunks = 5,\n                 max_pool_factor = 2,\n                 nchannels = [5, 32, 64, 128],\n                 n_hidden = 457,\n                 dropout = 0.2):\n\n        super(CNN_1d, self).__init__()\n        self.rf = 0 # running estimate of the receptive field\n        self.chunk_size = 1 # running estimate of num basepairs corresponding to one position after convolutions\n\n        conv_layers = []\n        for i in range(len(nchannels)-1):\n            conv_layers += [ nn.Conv1d(nchannels[i], nchannels[i+1], filter_widths[i], padding = 0),\n                        nn.BatchNorm1d(nchannels[i+1]), # tends to help give faster convergence: https://arxiv.org/abs/1502.03167\n                        nn.Dropout2d(dropout), # popular form of regularization: https://jmlr.org/papers/v15/srivastava14a.html\n                        nn.MaxPool1d(max_pool_factor),\n                        nn.ELU(inplace=True)  ] # popular alternative to ReLU: https://arxiv.org/abs/1511.07289\n            assert(filter_widths[i] % 2 == 1) # assume this\n            self.rf += (filter_widths[i] - 1) * self.chunk_size\n            #self.chunk_size *= max_pool_factor\n\n        # If you have a model with lots of layers, you can create a list first and\n        # then use the * operator to expand the list into positional arguments, like this:\n        self.conv_net = nn.Sequential(*conv_layers)\n\n        # Calculate the output size after convolutions and pooling\n        total_length = 457  # Assuming the width of the input matrix is 206\n        for filter_width in filter_widths:\n            total_length = (total_length - filter_width + 1) // max_pool_factor\n\n        # Calculate the correct number of features to pass to the first linear layer\n        conv_output_features = nchannels[-1] * total_length\n        self.dense_net = nn.Sequential(nn.Linear(conv_output_features, n_hidden),\n                                        nn.Dropout(dropout),\n                                        nn.ELU(inplace=True),\n                                        nn.Linear(n_hidden, n_output_channels))\n\n#         self.conv_net = nn.Sequential(*conv_layers)\n\n#         self.seq_len = num_chunks * self.chunk_size + self.rf # amount of sequence context required\n\n#         print(\"Receptive field:\", self.rf, \"Chunk size:\", self.chunk_size, \"Number chunks:\", num_chunks)\n\n#         self.dense_net = nn.Sequential( nn.Linear(nchannels[-1] * num_chunks, n_hidden),\n#                                         nn.Dropout(dropout),\n#                                         nn.ELU(inplace=True),\n#                                         nn.Linear(n_hidden, n_output_channels) )\n\n    def forward(self, x):\n        net = self.conv_net(x)\n        net = net.view(net.size(0), -1)\n        net = self.dense_net(net)\n        return(net)",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-12-17T00:08:48.124580Z",
          "iopub.status.idle": "2023-12-17T00:08:48.138189Z",
          "iopub.execute_input": "2023-12-17T00:08:48.125185Z",
          "shell.execute_reply": "2023-12-17T00:08:48.137189Z",
          "shell.execute_reply.started": "2023-12-17T00:08:48.125156Z"
        },
        "cell_id": "4a9833e647fc4ac49dcb9d10f217a1b9",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 8,
      "block_group": "8c60b05eae1c4477a637378eb72bcdb0"
    },
    {
      "cell_type": "code",
      "source": "CNN_1d()",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-12-17T00:08:48.139607Z",
          "iopub.status.idle": "2023-12-17T00:08:48.264668Z",
          "iopub.execute_input": "2023-12-17T00:08:48.140012Z",
          "shell.execute_reply": "2023-12-17T00:08:48.263711Z",
          "shell.execute_reply.started": "2023-12-17T00:08:48.139977Z"
        },
        "cell_id": "3b04939edd404e8292a1255987067195",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "CNN_1d(\n  (conv_net): Sequential(\n    (0): Conv1d(5, 32, kernel_size=(15,), stride=(1,))\n    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): Dropout2d(p=0.2, inplace=False)\n    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (4): ELU(alpha=1.0, inplace=True)\n    (5): Conv1d(32, 64, kernel_size=(15,), stride=(1,))\n    (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): Dropout2d(p=0.2, inplace=False)\n    (8): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (9): ELU(alpha=1.0, inplace=True)\n    (10): Conv1d(64, 128, kernel_size=(15,), stride=(1,))\n    (11): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (12): Dropout2d(p=0.2, inplace=False)\n    (13): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (14): ELU(alpha=1.0, inplace=True)\n  )\n  (dense_net): Sequential(\n    (0): Linear(in_features=5632, out_features=457, bias=True)\n    (1): Dropout(p=0.2, inplace=False)\n    (2): ELU(alpha=1.0, inplace=True)\n    (3): Linear(in_features=457, out_features=457, bias=True)\n  )\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "block_group": "b8fd608cb5e84a0fb9173f72318922a1"
    },
    {
      "cell_type": "code",
      "source": "def run_one_epoch(train_flag, dataloader, cnn_1d, optimizer, device=\"cuda\"):\n\n    torch.set_grad_enabled(train_flag)\n    cnn_1d.train() if train_flag else cnn_1d.eval()\n\n    losses = []\n    accuracies = []\n\n    for (x,y) in dataloader: # collection of tuples with iterator\n        x = x.float()\n        y = y.float()\n        (x, y) = ( x.to(device), y.to(device) ) # transfer data to GPU\n\n        output = cnn_1d(x) # forward pass\n        output = output.squeeze() # remove spurious channel dimension\n        loss = F.mse_loss(output, y).float()\n\n        if train_flag:\n            loss.backward() # back propagation\n            optimizer.step()\n            optimizer.zero_grad()\n\n        losses.append(loss.detach().cpu().numpy())\n        # accuracy = torch.mean( ( (output > 0.0) == (y > 0.5) ).float() ) # output is in logit space so threshold is 0.\n        # accuracies.append(accuracy.detach().cpu().numpy())\n\n    return( np.mean(losses))",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-12-17T00:08:48.265877Z",
          "iopub.status.idle": "2023-12-17T00:08:48.274114Z",
          "iopub.execute_input": "2023-12-17T00:08:48.266167Z",
          "shell.execute_reply": "2023-12-17T00:08:48.273166Z",
          "shell.execute_reply.started": "2023-12-17T00:08:48.266142Z"
        },
        "cell_id": "8e35dd07f15f4f8ba3c93aa290e9beeb",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 10,
      "block_group": "5fcbffcc45c74d1cb2d36c26b63045c0"
    },
    {
      "cell_type": "code",
      "source": "def train_model(cnn_1d, train_data, validation_data, epochs=100, patience=10, verbose = True): # lr = 0.001, weight_decay = 0\n    \"\"\"\n    Train a 1D CNN model and record accuracy metrics.\n    \"\"\"\n    # Move the model to the GPU here to make it runs there, and set \"device\" as above\n    # TODO CODE\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    cnn_1d.to(device)\n\n    # 1. Make new BedPeakDataset and DataLoader objects for both training and validation data.\n    # TODO CODE\n    #train_dataset = BedPeaksDataset(train_data, cnn_1d.seq_len)\n    #train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=10, num_workers = 0)\n    #validation_dataset = BedPeaksDataset(validation_data, cnn_1d.seq_len)\n    #validation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=1000)\n\n    # 2. Instantiates an optimizer for the model.\n    # TODO CODE\n    optimizer = torch.optim.Adam(cnn_1d.parameters(), amsgrad=True) # lr = lr weight_decay = weight_decay\n\n    # 3. Run the training loop with early stopping.\n    # TODO CODE\n    train_losses = []\n    validation_losses = []\n    patience_counter = patience\n    best_test_loss = np.inf\n    check_point_filename = 'cnn_1d_checkpoint.pt' # to save the best model fit to date\n    for epoch in range(epochs):\n        start_time = timeit.default_timer()\n        train_loss = run_one_epoch(True, train_dataloader, cnn_1d, optimizer, device)\n        validation_loss = run_one_epoch(False, validation_dataloader, cnn_1d, optimizer, device)\n        train_losses.append(train_loss)\n        validation_losses.append(validation_loss)\n        # train_accs.append(train_acc)\n        # val_accs.append(val_acc)\n        if validation_loss < best_test_loss:\n            torch.save(cnn_1d.state_dict(), check_point_filename)\n            best_test_loss = validation_loss\n            patience_counter = patience\n        else:\n            patience_counter -= 1\n            if patience_counter <= 0:\n                cnn_1d.load_state_dict(torch.load(check_point_filename)) # recover the best model so far\n                break\n        elapsed = float(timeit.default_timer() - start_time)\n        print(\"Epoch {} took {:.2f}s. Train loss: {:.4f}., Test loss: {:.4f}. Patience: {}\".format(epoch+1, elapsed, train_loss, validation_loss, patience_counter))\n\n    # 4. Return the fitted model (not strictly necessary since this happens \"in place\"), train and validation accuracies.\n    # TODO CODE\n    return(cnn_1d, train_losses, validation_losses)",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-12-17T00:08:48.279028Z",
          "iopub.status.idle": "2023-12-17T00:08:48.296091Z",
          "iopub.execute_input": "2023-12-17T00:08:48.279762Z",
          "shell.execute_reply": "2023-12-17T00:08:48.295012Z",
          "shell.execute_reply.started": "2023-12-17T00:08:48.279725Z"
        },
        "cell_id": "204b69f532114491867331536f2b41b6",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 11,
      "block_group": "df474bda3b7c4ccaa39560290876be92"
    },
    {
      "cell_type": "code",
      "source": "pip install dask_ml",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-12-17T00:08:48.297094Z",
          "iopub.status.idle": "2023-12-17T00:09:04.358243Z",
          "iopub.execute_input": "2023-12-17T00:08:48.297354Z",
          "shell.execute_reply": "2023-12-17T00:09:04.357058Z",
          "shell.execute_reply.started": "2023-12-17T00:08:48.297330Z"
        },
        "cell_id": "2f9d3448c35b4ac2b33f43669f660482",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting dask_ml\n  Downloading dask_ml-2023.3.24-py3-none-any.whl (148 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.7/148.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: dask[array,dataframe]>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from dask_ml) (2023.12.0)\nRequirement already satisfied: distributed>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from dask_ml) (2023.12.0)\nRequirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.10/site-packages (from dask_ml) (0.57.1)\nRequirement already satisfied: numpy>=1.20.0 in /opt/conda/lib/python3.10/site-packages (from dask_ml) (1.24.3)\nRequirement already satisfied: pandas>=0.24.2 in /opt/conda/lib/python3.10/site-packages (from dask_ml) (2.0.3)\nRequirement already satisfied: scikit-learn>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from dask_ml) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from dask_ml) (1.11.4)\nCollecting dask-glm>=0.2.0 (from dask_ml)\n  Obtaining dependency information for dask-glm>=0.2.0 from https://files.pythonhosted.org/packages/8a/8e/cd1502dd2d00d54fb3e10880d4c8cb6699320a239da7a39c9f55044afdee/dask_glm-0.3.2-py2.py3-none-any.whl.metadata\n  Downloading dask_glm-0.3.2-py2.py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: multipledispatch>=0.4.9 in /opt/conda/lib/python3.10/site-packages (from dask_ml) (1.0.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from dask_ml) (21.3)\nRequirement already satisfied: cloudpickle>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from dask-glm>=0.2.0->dask_ml) (2.2.1)\nCollecting sparse>=0.7.0 (from dask-glm>=0.2.0->dask_ml)\n  Downloading sparse-0.14.0-py2.py3-none-any.whl (80 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.0/81.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: click>=8.1 in /opt/conda/lib/python3.10/site-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (8.1.7)\nRequirement already satisfied: fsspec>=2021.09.0 in /opt/conda/lib/python3.10/site-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (2023.12.2)\nRequirement already satisfied: partd>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (1.4.1)\nRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (6.0.1)\nRequirement already satisfied: toolz>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (0.12.0)\nRequirement already satisfied: importlib-metadata>=4.13.0 in /opt/conda/lib/python3.10/site-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (6.8.0)\nRequirement already satisfied: jinja2>=2.10.3 in /opt/conda/lib/python3.10/site-packages (from distributed>=2.4.0->dask_ml) (3.1.2)\nRequirement already satisfied: locket>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from distributed>=2.4.0->dask_ml) (1.0.0)\nRequirement already satisfied: msgpack>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from distributed>=2.4.0->dask_ml) (1.0.5)\nRequirement already satisfied: psutil>=5.7.2 in /opt/conda/lib/python3.10/site-packages (from distributed>=2.4.0->dask_ml) (5.9.3)\nRequirement already satisfied: sortedcontainers>=2.0.5 in /opt/conda/lib/python3.10/site-packages (from distributed>=2.4.0->dask_ml) (2.4.0)\nRequirement already satisfied: tblib>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from distributed>=2.4.0->dask_ml) (3.0.0)\nRequirement already satisfied: tornado>=6.0.4 in /opt/conda/lib/python3.10/site-packages (from distributed>=2.4.0->dask_ml) (6.3.3)\nRequirement already satisfied: urllib3>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from distributed>=2.4.0->dask_ml) (1.26.15)\nRequirement already satisfied: zict>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from distributed>=2.4.0->dask_ml) (3.0.0)\nRequirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.0->dask_ml) (0.40.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->dask_ml) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24.2->dask_ml) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24.2->dask_ml) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24.2->dask_ml) (2023.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.2.0->dask_ml) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.2.0->dask_ml) (3.2.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=4.13.0->dask[array,dataframe]>=2.4.0->dask_ml) (3.16.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=2.10.3->distributed>=2.4.0->dask_ml) (2.1.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=0.24.2->dask_ml) (1.16.0)\nDownloading dask_glm-0.3.2-py2.py3-none-any.whl (13 kB)\nInstalling collected packages: sparse, dask-glm, dask_ml\nSuccessfully installed dask-glm-0.3.2 dask_ml-2023.3.24 sparse-0.14.0\nNote: you may need to restart the kernel to use updated packages.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 12,
      "block_group": "8448b35d82d84e14ab5f2ba11e9bba4e"
    },
    {
      "cell_type": "code",
      "source": "# apply SN-filter (with p_unpaired calculation), padding does not affect this block\nfrom dask_ml.model_selection import train_test_split\ndf_sn = ddf[ddf[\"SN_filter\"]==1]\n\n# split into 2A3 MaP and DMS MaP datasets\ndf_2A3 = df_sn[df_sn[\"experiment_type\"]==\"2A3_MaP\"]\ndf_DMS = df_sn[df_sn[\"experiment_type\"]==\"DMS_MaP\"]\n\n# split into train and test\nX_2A3_seq = df_2A3[\"sequence\"]\n#X_2A3 = df_2A3[\"sequence\"]\nX_2A3_p_unpaired = df_2A3.loc[:, \"p_unp_1\":\"p_unp_206\"]\n#X_2A3 = dd.concat([X_2A3_seq, X_2A3_p_unpaired])\n#print(X_2A3.shape)\ny_2A3 = df_2A3.loc[:, df_2A3.columns.str.fullmatch(\"reactivity_\\d\\d\\d\\d\")]\nX_2A3_train_seq, X_2A3_test_seq, X_2A3_train_p_unpaired, X_2A3_test_p_unpaired, y_2A3_train, y_2A3_test = train_test_split(X_2A3_seq, X_2A3_p_unpaired, y_2A3, test_size=0.2, shuffle=True, blockwise=True, random_state=42)\nX_2A3_train_seq, X_2A3_validation_seq, X_2A3_train_p_unpaired, X_2A3_validation_p_unpaired, y_2A3_train, y_2A3_validation = train_test_split(X_2A3_train_seq, X_2A3_train_p_unpaired, y_2A3_train, test_size=0.25, shuffle=True, blockwise=True, random_state=42)\n\nX_DMS_seq = df_DMS[\"sequence\"]\n#X_DMS = df_DMS[\"sequence\"]\nX_DMS_p_unpaired = df_DMS.loc[:, \"p_unp_1\":\"p_unp_206\"]\n#X_DMS = dd.concat([X_DMS_seq, X_DMS_p_unpaired])\n#print(X_DMS.shape)\ny_DMS = df_DMS.loc[:, df_DMS.columns.str.fullmatch(\"reactivity_\\d\\d\\d\\d\")]\nX_DMS_train_seq, X_DMS_test_seq, X_DMS_train_p_unpaired, X_DMS_test_p_unpaired, y_DMS_train, y_DMS_test = train_test_split(X_DMS_seq, X_DMS_p_unpaired, y_DMS, test_size=0.2, shuffle=True, blockwise=True, random_state=42)\nX_DMS_train_seq, X_DMS_validation_seq, X_DMS_train_p_unpaired, X_DMS_validation_p_unpaired, y_DMS_train, y_DMS_validation = train_test_split(X_DMS_train_seq, X_DMS_train_p_unpaired, y_DMS_train, test_size=0.25, shuffle=True, blockwise=True, random_state=42)",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-12-17T00:09:04.360038Z",
          "iopub.status.idle": "2023-12-17T00:09:06.017056Z",
          "iopub.execute_input": "2023-12-17T00:09:04.361005Z",
          "shell.execute_reply": "2023-12-17T00:09:06.016061Z",
          "shell.execute_reply.started": "2023-12-17T00:09:04.360972Z"
        },
        "cell_id": "56b62438064b4ded906eb42078bd8c98",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 13,
      "block_group": "683e54187b444a059656fc0733b556b8"
    },
    {
      "cell_type": "code",
      "source": "def df_toArray(ddf1A, ddf1B, ddf2): # for sequence, p_unpaired, and reactivity. Padding does not affect this block\n    subset_columns = []\n    for i in range(457): #206 vs 457\n        subset_columns.append(\"reactivity_0\"+str(i+1).zfill(3))\n\n    # Use .to_dask_array() to convert the subset of the DataFrame to a Dask Array\n    # subset = small_set[subset_columns]\n\n    # Compute the subset of the Dask DataFrame and convert it to a Pandas DataFrame\n    reactivities = ddf2.compute().to_numpy()\n    p_unpaired = ddf1B.compute().to_numpy()\n\n    row_means = np.nanmean(reactivities, axis=1)\n\n    # Iterate over each element and replace NaN with the row mean\n    for i, row in enumerate(reactivities):\n        mask = np.isnan(row)\n        reactivities[i, mask] = row_means[i]\n\n    reactivities\n\n    seqs = ddf1A.compute().tolist()\n\n    return seqs, p_unpaired, reactivities\n\n# df_toArray(X_2A3_train, y_2A3_train)",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-12-17T00:09:06.018733Z",
          "iopub.status.idle": "2023-12-17T00:09:06.029268Z",
          "iopub.execute_input": "2023-12-17T00:09:06.019475Z",
          "shell.execute_reply": "2023-12-17T00:09:06.028265Z",
          "shell.execute_reply.started": "2023-12-17T00:09:06.019431Z"
        },
        "cell_id": "7803c474385546b38cf11c303774100b",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 14,
      "block_group": "2cd84fdd4bbd456b98dc11efb462c80b"
    },
    {
      "cell_type": "code",
      "source": "# For p_unpaired 2A3. Padding does not affect this block.\n\nseqs, p_unpaired, reactivities = df_toArray(X_2A3_train_seq, X_2A3_train_p_unpaired, y_2A3_train)\ntrain_dataset = BedPeaksDataset(seqs, p_unpaired, reactivities)\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=1000, num_workers = 0)\n\nseqs, p_unpaired, reactivities = df_toArray(X_2A3_validation_seq, X_2A3_validation_p_unpaired, y_2A3_validation)\nvalidation_dataset = BedPeaksDataset(seqs, p_unpaired, reactivities)\nvalidation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=1000, num_workers = 0)\n\nseqs, p_unpaired, reactivities = df_toArray(X_2A3_test_seq, X_2A3_test_p_unpaired, y_2A3_test)\ntest_dataset = BedPeaksDataset(seqs, p_unpaired, reactivities)\ntest_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, num_workers = 0)",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-12-17T00:20:55.651447Z",
          "iopub.status.idle": "2023-12-17T00:36:04.215304Z",
          "iopub.execute_input": "2023-12-17T00:20:55.651874Z",
          "shell.execute_reply": "2023-12-17T00:36:04.214219Z",
          "shell.execute_reply.started": "2023-12-17T00:20:55.651836Z"
        },
        "cell_id": "8be27813b9314829ae6865c6a2260083",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 18,
      "block_group": "cca524b5db474e7797accd89a041a61f"
    },
    {
      "cell_type": "code",
      "source": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-12-17T00:20:50.369018Z",
          "iopub.status.idle": "2023-12-17T00:20:50.452425Z",
          "iopub.execute_input": "2023-12-17T00:20:50.369738Z",
          "shell.execute_reply": "2023-12-17T00:20:50.451453Z",
          "shell.execute_reply.started": "2023-12-17T00:20:50.369702Z"
        },
        "cell_id": "7c55938331094fc6a05adb017eba32de",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "cuda\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 17,
      "block_group": "d268007c0f94411eb82c22523b4a56d6"
    },
    {
      "cell_type": "code",
      "source": "import timeit\nmy_cnn1d_2A3 = CNN_1d()\n# print(my_cnn1d.seq_le\nmy_cnn1d_2A3 = my_cnn1d_2A3.float()\nmy_cnn1d_2A3, train_losses, test_losses = train_model(my_cnn1d_2A3, train_dataloader, validation_dataloader) # lr = 0.001 weight_decay = 0",
      "metadata": {
        "trusted": true,
        "cell_id": "a032e6a55d644b6b9f7e71bedee30681",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null,
      "block_group": "9cd8f2bd114f43119c23d5608f3debbf"
    },
    {
      "cell_type": "code",
      "source": "# For p_unpaired DMS. Padding does not affect this block.\n\nseqs, p_unpaired, reactivities = df_toArray(X_DMS_train_seq, X_DMS_train_p_unpaired, y_DMS_train)\ntrain_dataset = BedPeaksDataset(seqs, p_unpaired, reactivities)\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=1000, num_workers = 0)\n\nseqs, p_unpaired, reactivities = df_toArray(X_DMS_validation_seq, X_DMS_validation_p_unpaired, y_DMS_validation)\nvalidation_dataset = BedPeaksDataset(seqs, p_unpaired, reactivities)\nvalidation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=1000, num_workers = 0)\n\nseqs, p_unpaired, reactivities = df_toArray(X_DMS_test_seq, X_DMS_test_p_unpaired, y_DMS_test)\ntest_dataset = BedPeaksDataset(seqs, p_unpaired, reactivities)\ntest_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, num_workers = 0)",
      "metadata": {
        "trusted": true,
        "cell_id": "a6331dd91bfa4baf85d54d953b8075f6",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null,
      "block_group": "2c8364d7ba734385b9efe46a9842e241"
    },
    {
      "cell_type": "code",
      "source": "import timeit\nmy_cnn1d_DMS = CNN_1d()\n# print(my_cnn1d.seq_le\nmy_cnn1d_DMS = my_cnn1d_DMS.float()\nmy_cnn1d_DMS, train_losses, test_losses = train_model(my_cnn1d_DMS, train_dataloader, validation_dataloader) # lr = 0.001 weight_decay = 0",
      "metadata": {
        "trusted": true,
        "cell_id": "c34a0875d58541bd96f9a4a1c4239310",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null,
      "block_group": "b22299cae21645a58afe1ab42a7eec6b"
    },
    {
      "cell_type": "code",
      "source": "ddf = dd.read_csv('/kaggle/input/rna-data/test_seq_p_unp.csv')\n# test_ddf = ddf.sort_values(by='id_min')\nddf.head()",
      "metadata": {
        "trusted": true,
        "cell_id": "104e8666a8294c1cb16aa7d0bc3a9025",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null,
      "block_group": "d1f4f9e7dfbe4d43bdc183f92774c819"
    },
    {
      "cell_type": "code",
      "source": "id_min_list = ddf['id_min'].compute().tolist()\nid_max_list = ddf['id_max'].compute().tolist()",
      "metadata": {
        "trusted": true,
        "cell_id": "3248eee9128f41baa5f06da442d4b2c1",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null,
      "block_group": "a66d9ccec4c24561be0848d44ebb65df"
    },
    {
      "cell_type": "code",
      "source": "# split into train and test\ntest_seq = ddf[\"sequence\"]\n#X_2A3 = df_2A3[\"sequence\"]\ntest_p_unpaired = ddf.loc[:, \"p_unp_1\":\"p_unp_457\"]",
      "metadata": {
        "trusted": true,
        "cell_id": "24b87d21a54f4666a597ce264c0b2768",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null,
      "block_group": "d3f4b1170435493094541e6a603a813f"
    },
    {
      "cell_type": "code",
      "source": "def df_toArray_test(ddf1A, ddf1B): # for sequence, p_unpaired, and reactivity. Padding does not affect this block\n    subset_columns = []\n    for i in range(457): #206 vs 457\n        subset_columns.append(\"reactivity_0\"+str(i+1).zfill(3))\n\n    # Use .to_dask_array() to convert the subset of the DataFrame to a Dask Array\n    # subset = small_set[subset_columns]\n\n    # Compute the subset of the Dask DataFrame and convert it to a Pandas DataFrame\n    p_unpaired = ddf1B.to_numpy()\n\n\n    seqs = ddf1A.tolist()\n\n    return seqs, p_unpaired",
      "metadata": {
        "trusted": true,
        "cell_id": "4fd15e3d27494bb6a3e77e80c1e92d67",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null,
      "block_group": "0b89a12d487749f8aa4f1b3c41dd216d"
    },
    {
      "cell_type": "code",
      "source": "class BedPeaksDataset(torch.utils.data.IterableDataset):\n\n    def __init__(self, seq, p_unpaired):\n        super(BedPeaksDataset, self).__init__()\n        self.seq = seq\n        self.p_unpaired = p_unpaired\n\n    def __iter__(self):\n        for i in range(len(self.seq)):\n            yield(one_hot(self.seq[i], self.p_unpaired[i])) # positive example\n",
      "metadata": {
        "trusted": true,
        "cell_id": "649fbdabdcff447789c7a2fa0e1084c3",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null,
      "block_group": "91b368e46d4c413a86515097b82c75a1"
    },
    {
      "cell_type": "code",
      "source": "seqs, p_unpaired = df_toArray_test(test_seq, test_p_unpaired)\ntest_dataset = BedPeaksDataset(seqs, p_unpaired)\ntest_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, num_workers = 0, shuffle = False)",
      "metadata": {
        "trusted": true,
        "cell_id": "f8a3511562be4135ac8c98d077004519",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null,
      "block_group": "a2ea0ce256d14c3cba67795b1df44340"
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\n\n# Create an empty DataFrame with the specific column names\ndf_output = pd.DataFrame(columns=['id', 'reactivity_DMS_MaP', 'reactivity_2A3_MaP'])",
      "metadata": {
        "trusted": true,
        "cell_id": "3f5b81862bba4b7bad4960a49a884a16",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null,
      "block_group": "cdebb6a6b7494bbcbce5053731f9ae57"
    },
    {
      "cell_type": "code",
      "source": "#test\nmy_cnn1d_DMS.eval()\nmy_cnn1d_2A3.eval()\nfor x in test_dataloader: # collection of tuples with iterator\n    x = x.float()\n\n    output1 = my_cnn1d_DMS(x) # forward pass\n    output2 = my_cnn1d_2A3(x)\n    index_start = id_min_list.pop(0)\n    index_end = id_max_list.pop(0)\n    for i in range(index_start, index_end+1):\n        new_row = {'id': i, 'reactivity_DMS_MaP': output1[0][i-index_start].item(), 'reactivity_2A3_MaP': output2[0][i-index_start].item()}\n        df_output = pd.concat([df_output, pd.DataFrame([new_row])], ignore_index=True)",
      "metadata": {
        "trusted": true,
        "cell_id": "49ed1b00eeb44f158370a837ec77ded3",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null,
      "block_group": "d5ad6d023683465ea19f1b5e8ed2df05"
    },
    {
      "cell_type": "code",
      "source": "df_output",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-12-17T00:19:54.417954Z",
          "iopub.status.idle": "2023-12-17T00:19:54.418262Z",
          "shell.execute_reply": "2023-12-17T00:19:54.418122Z",
          "shell.execute_reply.started": "2023-12-17T00:19:54.418108Z"
        },
        "cell_id": "43d0b14926da40b194c29a8da83b0511",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null,
      "block_group": "2bab9e84951d4c0f9d5278a4b4c63b38"
    },
    {
      "cell_type": "code",
      "source": "df_output.to_csv('/kaggle/working/df_output.csv',index=False)",
      "metadata": {
        "trusted": true,
        "cell_id": "02b4b6ceacd249e19e8382c5c09723d8",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null,
      "block_group": "9df8df1987f7404bb281ddd563d0b670"
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=fe343e39-d2c0-4296-915d-091d9a42752d' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kaggle": {
      "language": "python",
      "sourceType": "notebook",
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 51294,
          "sourceType": "competition",
          "databundleVersionId": 6923401
        },
        {
          "sourceId": 7218472,
          "datasetId": 4177787,
          "sourceType": "datasetVersion"
        }
      ],
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "dockerImageVersionId": 30627
    },
    "deepnote": {},
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "file_extension": ".py",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "nbconvert_exporter": "python"
    },
    "deepnote_notebook_id": "75c42d05def54ea1a6da08f38b2f2f4a",
    "deepnote_execution_queue": []
  }
}