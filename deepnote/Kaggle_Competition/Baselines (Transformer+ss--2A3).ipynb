{
  "cells": [
    {
      "cell_type": "code",
      "source": "# import the libraries\nimport numpy as np\nimport dask.dataframe as dd\nfrom dask.diagnostics import ProgressBar\nfrom itertools import product\nimport matplotlib.pyplot as plt",
      "metadata": {
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-12-17T04:21:59.219100Z",
          "iopub.status.idle": "2023-12-17T04:22:03.263823Z",
          "iopub.execute_input": "2023-12-17T04:21:59.219443Z",
          "shell.execute_reply": "2023-12-17T04:22:03.263009Z"
        },
        "papermill": {
          "status": "completed",
          "duration": 4.054215,
          "end_time": "2023-12-17T04:22:03.266047",
          "exception": false,
          "start_time": "2023-12-17T04:21:59.211832"
        },
        "cell_id": "442d8a7ffb284604904984eaa1e32b45",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
        }
      ],
      "execution_count": 1,
      "block_group": "2563812c475541ef96a73cf412d3211e"
    },
    {
      "cell_type": "code",
      "source": "# import, shuffle, and see the data\nddf = dd.read_csv('/kaggle/input/test-and-train-punpaired-dataset/train_data_p_unp.csv').iloc[:, 1:]\nshfl_ddf = ddf.sample(frac = 1, random_state = 42)\nshfl_ddf.head()",
      "metadata": {
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-12-17T04:22:03.278784Z",
          "iopub.status.idle": "2023-12-17T04:22:06.630684Z",
          "iopub.execute_input": "2023-12-17T04:22:03.279447Z",
          "shell.execute_reply": "2023-12-17T04:22:06.629580Z"
        },
        "papermill": {
          "status": "completed",
          "duration": 3.360838,
          "end_time": "2023-12-17T04:22:06.632945",
          "exception": false,
          "start_time": "2023-12-17T04:22:03.272107"
        },
        "cell_id": "93a5309f3a9740bf9b1b0cbfd0d5e467",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sequence_id</th>\n      <th>sequence</th>\n      <th>experiment_type</th>\n      <th>dataset_name</th>\n      <th>reads</th>\n      <th>signal_to_noise</th>\n      <th>SN_filter</th>\n      <th>reactivity_0001</th>\n      <th>reactivity_0002</th>\n      <th>reactivity_0003</th>\n      <th>...</th>\n      <th>p_unp_197</th>\n      <th>p_unp_198</th>\n      <th>p_unp_199</th>\n      <th>p_unp_200</th>\n      <th>p_unp_201</th>\n      <th>p_unp_202</th>\n      <th>p_unp_203</th>\n      <th>p_unp_204</th>\n      <th>p_unp_205</th>\n      <th>p_unp_206</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5420</th>\n      <td>ab587c2d24eb</td>\n      <td>GGGAACGACUCGAGUAGAGUCGAAAAGGCCUAGGGCGGGCGGGAAU...</td>\n      <td>DMS_MaP</td>\n      <td>DasLabBigLib_OneMil_OpenKnot_Round_2_train_DMS</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>16450</th>\n      <td>309b8583b119</td>\n      <td>GGGAACGACUCGAGUAGAGUCGAAAAAAGACCUACAUACAUUGUAU...</td>\n      <td>2A3_MaP</td>\n      <td>DasLabBigLib_OneMil_Coronavirus_genomes_SARS_r...</td>\n      <td>162</td>\n      <td>0.538</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4544</th>\n      <td>4ed1f0557392</td>\n      <td>GGGAACGACUCGAGUAGAGUCGAAAAGCUGAUUGCCUGGCGGCUAC...</td>\n      <td>2A3_MaP</td>\n      <td>DasLabBigLib_OneMil_OpenKnot_Round_2_train_2A3</td>\n      <td>702</td>\n      <td>1.553</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>17837</th>\n      <td>93235436cac4</td>\n      <td>GGGAACGACUCGAGUAGAGUCGAAAAAUUAUUAGAAGGGGGUAAUG...</td>\n      <td>2A3_MaP</td>\n      <td>DasLabBigLib_OneMil_OpenKnot_Round_2_train_2A3</td>\n      <td>3</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>14752</th>\n      <td>969913b8537c</td>\n      <td>GGGAACGACUCGAGUAGAGUCGAAAACAUGGUCACCACUGUUGGCG...</td>\n      <td>2A3_MaP</td>\n      <td>DasLabBigLib_OneMil_Coronavirus_genomes_SARS_r...</td>\n      <td>504</td>\n      <td>0.910</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 625 columns</p>\n</div>",
            "text/plain": "        sequence_id                                           sequence  \\\n5420   ab587c2d24eb  GGGAACGACUCGAGUAGAGUCGAAAAGGCCUAGGGCGGGCGGGAAU...   \n16450  309b8583b119  GGGAACGACUCGAGUAGAGUCGAAAAAAGACCUACAUACAUUGUAU...   \n4544   4ed1f0557392  GGGAACGACUCGAGUAGAGUCGAAAAGCUGAUUGCCUGGCGGCUAC...   \n17837  93235436cac4  GGGAACGACUCGAGUAGAGUCGAAAAAUUAUUAGAAGGGGGUAAUG...   \n14752  969913b8537c  GGGAACGACUCGAGUAGAGUCGAAAACAUGGUCACCACUGUUGGCG...   \n\n      experiment_type                                       dataset_name  \\\n5420          DMS_MaP     DasLabBigLib_OneMil_OpenKnot_Round_2_train_DMS   \n16450         2A3_MaP  DasLabBigLib_OneMil_Coronavirus_genomes_SARS_r...   \n4544          2A3_MaP     DasLabBigLib_OneMil_OpenKnot_Round_2_train_2A3   \n17837         2A3_MaP     DasLabBigLib_OneMil_OpenKnot_Round_2_train_2A3   \n14752         2A3_MaP  DasLabBigLib_OneMil_Coronavirus_genomes_SARS_r...   \n\n       reads  signal_to_noise  SN_filter  reactivity_0001  reactivity_0002  \\\n5420       0            0.000          0              NaN              NaN   \n16450    162            0.538          0              NaN              NaN   \n4544     702            1.553          1              NaN              NaN   \n17837      3            0.000          0              NaN              NaN   \n14752    504            0.910          0              NaN              NaN   \n\n       reactivity_0003  ...  p_unp_197  p_unp_198  p_unp_199  p_unp_200  \\\n5420               NaN  ...        1.0        1.0        1.0        1.0   \n16450              NaN  ...        1.0        1.0        1.0        1.0   \n4544               NaN  ...        1.0        1.0        1.0        1.0   \n17837              NaN  ...        1.0        1.0        1.0        1.0   \n14752              NaN  ...        1.0        1.0        1.0        1.0   \n\n       p_unp_201  p_unp_202  p_unp_203  p_unp_204  p_unp_205  p_unp_206  \n5420         1.0        1.0        1.0        1.0        1.0        1.0  \n16450        1.0        1.0        1.0        1.0        1.0        1.0  \n4544         1.0        1.0        1.0        1.0        1.0        1.0  \n17837        1.0        1.0        1.0        1.0        1.0        1.0  \n14752        1.0        1.0        1.0        1.0        1.0        1.0  \n\n[5 rows x 625 columns]"
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 2,
      "block_group": "24624d04029e424c96d18f396581c09e"
    },
    {
      "cell_type": "code",
      "source": "dms_ddf = ddf.loc[ddf['experiment_type'] == \"DMS_MaP\"]\ntwoa3_ddf = ddf.loc[ddf['experiment_type'] == \"2A3_MaP\"]\ndms_ddf.head()",
      "metadata": {
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-12-17T04:22:06.646992Z",
          "iopub.status.idle": "2023-12-17T04:22:08.703788Z",
          "iopub.execute_input": "2023-12-17T04:22:06.647572Z",
          "shell.execute_reply": "2023-12-17T04:22:08.702789Z"
        },
        "papermill": {
          "status": "completed",
          "duration": 2.066407,
          "end_time": "2023-12-17T04:22:08.705876",
          "exception": false,
          "start_time": "2023-12-17T04:22:06.639469"
        },
        "cell_id": "2ac56e87cf804008aebea0bf273bcb77",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sequence_id</th>\n      <th>sequence</th>\n      <th>experiment_type</th>\n      <th>dataset_name</th>\n      <th>reads</th>\n      <th>signal_to_noise</th>\n      <th>SN_filter</th>\n      <th>reactivity_0001</th>\n      <th>reactivity_0002</th>\n      <th>reactivity_0003</th>\n      <th>...</th>\n      <th>p_unp_197</th>\n      <th>p_unp_198</th>\n      <th>p_unp_199</th>\n      <th>p_unp_200</th>\n      <th>p_unp_201</th>\n      <th>p_unp_202</th>\n      <th>p_unp_203</th>\n      <th>p_unp_204</th>\n      <th>p_unp_205</th>\n      <th>p_unp_206</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14</th>\n      <td>70cdf97f6392</td>\n      <td>GGGAACGACUCGAGUAGAGUCGAAAACCUGGAGGAGGAUGGAACAC...</td>\n      <td>DMS_MaP</td>\n      <td>PK50_AltChemMap_NovaSeq_DMS</td>\n      <td>103505</td>\n      <td>35.334</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>bad76a72215c</td>\n      <td>GGGAACGACUCGAGUAGAGUCGAAAAUAAAUUCAGCGGUAAUUCCU...</td>\n      <td>DMS_MaP</td>\n      <td>PK50_AltChemMap_NovaSeq_DMS</td>\n      <td>12725</td>\n      <td>8.874</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>f037cc8df765</td>\n      <td>GGGAACGACUCGAGUAGAGUCGAAAAUACCGAGAAAGAUCCUCGGU...</td>\n      <td>DMS_MaP</td>\n      <td>PK50_AltChemMap_NovaSeq_DMS</td>\n      <td>60600</td>\n      <td>24.826</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>e63fe5ebb069</td>\n      <td>GGGAACGACUCGAGUAGAGUCGAAAACGGGCAAACUAGAAAAGCCC...</td>\n      <td>DMS_MaP</td>\n      <td>PK50_AltChemMap_NovaSeq_DMS</td>\n      <td>16034</td>\n      <td>13.426</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>a4a9f51c982e</td>\n      <td>GGGAACGACUCGAGUAGAGUCGAAAAGGGUCCAGCCUGGAAAGGCU...</td>\n      <td>DMS_MaP</td>\n      <td>PK50_AltChemMap_NovaSeq_DMS</td>\n      <td>306828</td>\n      <td>41.648</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 625 columns</p>\n</div>",
            "text/plain": "     sequence_id                                           sequence  \\\n14  70cdf97f6392  GGGAACGACUCGAGUAGAGUCGAAAACCUGGAGGAGGAUGGAACAC...   \n15  bad76a72215c  GGGAACGACUCGAGUAGAGUCGAAAAUAAAUUCAGCGGUAAUUCCU...   \n16  f037cc8df765  GGGAACGACUCGAGUAGAGUCGAAAAUACCGAGAAAGAUCCUCGGU...   \n17  e63fe5ebb069  GGGAACGACUCGAGUAGAGUCGAAAACGGGCAAACUAGAAAAGCCC...   \n18  a4a9f51c982e  GGGAACGACUCGAGUAGAGUCGAAAAGGGUCCAGCCUGGAAAGGCU...   \n\n   experiment_type                 dataset_name   reads  signal_to_noise  \\\n14         DMS_MaP  PK50_AltChemMap_NovaSeq_DMS  103505           35.334   \n15         DMS_MaP  PK50_AltChemMap_NovaSeq_DMS   12725            8.874   \n16         DMS_MaP  PK50_AltChemMap_NovaSeq_DMS   60600           24.826   \n17         DMS_MaP  PK50_AltChemMap_NovaSeq_DMS   16034           13.426   \n18         DMS_MaP  PK50_AltChemMap_NovaSeq_DMS  306828           41.648   \n\n    SN_filter  reactivity_0001  reactivity_0002  reactivity_0003  ...  \\\n14          1              NaN              NaN              NaN  ...   \n15          1              NaN              NaN              NaN  ...   \n16          1              NaN              NaN              NaN  ...   \n17          1              NaN              NaN              NaN  ...   \n18          1              NaN              NaN              NaN  ...   \n\n    p_unp_197  p_unp_198  p_unp_199  p_unp_200  p_unp_201  p_unp_202  \\\n14        1.0        1.0        1.0        1.0        1.0        1.0   \n15        1.0        1.0        1.0        1.0        1.0        1.0   \n16        1.0        1.0        1.0        1.0        1.0        1.0   \n17        1.0        1.0        1.0        1.0        1.0        1.0   \n18        1.0        1.0        1.0        1.0        1.0        1.0   \n\n    p_unp_203  p_unp_204  p_unp_205  p_unp_206  \n14        1.0        1.0        1.0        1.0  \n15        1.0        1.0        1.0        1.0  \n16        1.0        1.0        1.0        1.0  \n17        1.0        1.0        1.0        1.0  \n18        1.0        1.0        1.0        1.0  \n\n[5 rows x 625 columns]"
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 3,
      "block_group": "7f2b9968b63e4a40a6c80f1253d4f6db"
    },
    {
      "cell_type": "code",
      "source": "# Modified version to account for probability of unpaired bases from secondary structure predictor\nbases={'A':0, 'C':1, 'G':2, 'U':3 }\n\ndef one_hot(string, p_unpaired):\n\n    res = np.zeros((5, 206), # Now there are 5 rows in the input vector, 457 is maximum length\n                   dtype=np.float32)\n    res[4, :] = 1\n\n    for j in range(len(string)):\n        if string[j] in bases: # bases can be 'N' signifying missing: this corresponds to all 0 in the encoding\n            res[ bases[ string[j] ], j ]= 1.\n        res[4, j] = p_unpaired[j]\n\n    return res",
      "metadata": {
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-12-17T04:22:08.721547Z",
          "iopub.status.idle": "2023-12-17T04:22:08.728008Z",
          "iopub.execute_input": "2023-12-17T04:22:08.721917Z",
          "shell.execute_reply": "2023-12-17T04:22:08.727106Z"
        },
        "papermill": {
          "status": "completed",
          "duration": 0.016783,
          "end_time": "2023-12-17T04:22:08.729930",
          "exception": false,
          "start_time": "2023-12-17T04:22:08.713147"
        },
        "cell_id": "79cd1bcf493840098d1c291c79e5dcb9",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 4,
      "block_group": "d0d385cfa2c24842af035d303541ced7"
    },
    {
      "cell_type": "code",
      "source": "# For p_unpaired data (changed the yield output)\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass BedPeaksDataset(torch.utils.data.IterableDataset):\n\n    def __init__(self, seq, p_unpaired, reactivities):\n        super(BedPeaksDataset, self).__init__()\n        self.seq = seq\n        self.reactivities = reactivities\n        self.p_unpaired = p_unpaired\n\n    def __iter__(self):\n        for i in range(len(self.seq)):\n            yield(one_hot(self.seq[i], self.p_unpaired[i]), self.reactivities[i]) # positive example",
      "metadata": {
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-12-17T04:22:08.744999Z",
          "iopub.status.idle": "2023-12-17T04:22:11.952100Z",
          "iopub.execute_input": "2023-12-17T04:22:08.745765Z",
          "shell.execute_reply": "2023-12-17T04:22:11.951095Z"
        },
        "papermill": {
          "status": "completed",
          "duration": 3.217125,
          "end_time": "2023-12-17T04:22:11.954385",
          "exception": false,
          "start_time": "2023-12-17T04:22:08.737260"
        },
        "cell_id": "3e2df60453fe412f9b70a623b3a8c8e9",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 5,
      "block_group": "e2192d8aa103476b8ea73fb880306e04"
    },
    {
      "cell_type": "code",
      "source": "def run_one_epoch(train_flag, dataloader, cnn_1d, optimizer, device=\"cuda\"):\n\n    torch.set_grad_enabled(train_flag)\n    cnn_1d.train() if train_flag else cnn_1d.eval()\n\n    losses = []\n    accuracies = []\n\n    size = len(dataloader.dataset.seq)\n    for batch, (x,y) in enumerate(dataloader): # collection of tuples with iterator\n        x = x.float()\n        y = y.float()\n        (x, y) = ( x.to(device), y.to(device) ) # transfer data to GPU\n\n        output = cnn_1d(x,y) # forward pass\n        output = output.squeeze() # remove spurious channel dimension\n        loss = F.mse_loss(output, y).float()\n\n        if train_flag:\n            loss.backward() # back propagation\n            optimizer.step()\n            optimizer.zero_grad()\n            \n            #current = batch * len(x)\n            #print(f\"[{current:>5d}/{size:>5d}]\")\n\n        losses.append(loss.detach().cpu().numpy())\n\n    return( np.mean(losses))",
      "metadata": {
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-12-17T04:22:11.968933Z",
          "iopub.status.idle": "2023-12-17T04:22:11.977256Z",
          "iopub.execute_input": "2023-12-17T04:22:11.969941Z",
          "shell.execute_reply": "2023-12-17T04:22:11.976465Z"
        },
        "papermill": {
          "status": "completed",
          "duration": 0.01784,
          "end_time": "2023-12-17T04:22:11.979148",
          "exception": false,
          "start_time": "2023-12-17T04:22:11.961308"
        },
        "cell_id": "f41c791a70194ff186a385ac26001a0b",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 6,
      "block_group": "41b8d9c332a64518b22f7019a5100f18"
    },
    {
      "cell_type": "code",
      "source": "def train_model(cnn_1d, train_dataloader, valid_dataloader, epochs=100, patience=10, verbose = True, lr = 0.001, weight_decay = 0):\n    \"\"\"\n    Train a 1D CNN model and record accuracy metrics.\n    \"\"\"\n    # Move the model to the GPU here to make it runs there, and set \"device\" as above\n    # TODO CODE\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    cnn_1d.to(device)\n\n    # 1. Make new BedPeakDataset and DataLoader objects for both training and validation data.\n    # TODO CODE\n    # train_dataset = BedPeaksDataset(train_data, genome, cnn_1d.seq_len)\n    # train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=10, num_workers = 0)\n    # validation_dataset = BedPeaksDataset(validation_data, genome, cnn_1d.seq_len)\n    # validation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=1000)\n\n    # 2. Instantiates an optimizer for the model.\n    # TODO CODE\n    optimizer = torch.optim.Adam(cnn_1d.parameters(), amsgrad=True, lr = lr, weight_decay = weight_decay)\n\n    # 3. Run the training loop with early stopping.\n    # TODO CODE\n    train_losses = []\n    valid_losses = []\n    # patience_counter = patience\n    best_valid_loss = np.inf\n    check_point_filename = 'cnn_1d_checkpoint.pt' # to save the best model fit to date\n    for epoch in range(epochs):\n        start_time = timeit.default_timer()\n        train_loss = run_one_epoch(True, train_dataloader, cnn_1d, optimizer, device)\n        valid_loss = run_one_epoch(False, valid_dataloader, cnn_1d, optimizer, device)\n        train_losses.append(train_loss)\n        valid_losses.append(valid_loss)\n        if valid_loss < best_valid_loss:\n            torch.save(cnn_1d.state_dict(), check_point_filename)\n            best_valid_loss = valid_loss\n            patience_counter = patience\n        else:\n            patience_counter -= 1\n            if patience_counter <= 0:\n                cnn_1d.load_state_dict(torch.load(check_point_filename)) # recover the best model so far\n                break\n        elapsed = float(timeit.default_timer() - start_time)\n        print(\"Epoch {} took {:.2f}s. Train loss: {:.4f}., Valid loss: {:.4f}. Patience: {}\".format(epoch+1, elapsed, train_loss, valid_loss, patience_counter))\n\n    # 4. Return the fitted model (not strictly necessary since this happens \"in place\"), train and validation accuracies.\n    # TODO CODE\n    return(cnn_1d, train_losses, valid_losses)",
      "metadata": {
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-12-17T04:22:11.994195Z",
          "iopub.status.idle": "2023-12-17T04:22:12.005411Z",
          "iopub.execute_input": "2023-12-17T04:22:11.994481Z",
          "shell.execute_reply": "2023-12-17T04:22:12.004492Z"
        },
        "papermill": {
          "status": "completed",
          "duration": 0.021338,
          "end_time": "2023-12-17T04:22:12.007448",
          "exception": false,
          "start_time": "2023-12-17T04:22:11.986110"
        },
        "cell_id": "73d1a2f8f3bf40db8419342aa4b1503c",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 7,
      "block_group": "6fc7547210e646e28f4612671cc6cee7"
    },
    {
      "cell_type": "code",
      "source": "! pip install dask_ml",
      "metadata": {
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-12-17T04:22:12.021771Z",
          "iopub.status.idle": "2023-12-17T04:22:26.061583Z",
          "iopub.execute_input": "2023-12-17T04:22:12.022064Z",
          "shell.execute_reply": "2023-12-17T04:22:26.060443Z"
        },
        "papermill": {
          "status": "completed",
          "duration": 14.049718,
          "end_time": "2023-12-17T04:22:26.064010",
          "exception": false,
          "start_time": "2023-12-17T04:22:12.014292"
        },
        "cell_id": "ac6d043896b44ac3b747e9ddcf055788",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Collecting dask_ml\r\n  Downloading dask_ml-2023.3.24-py3-none-any.whl (148 kB)\r\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.7/148.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hRequirement already satisfied: dask[array,dataframe]>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from dask_ml) (2023.11.0)\r\nRequirement already satisfied: distributed>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from dask_ml) (2023.11.0)\r\nRequirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.10/site-packages (from dask_ml) (0.57.1)\r\nRequirement already satisfied: numpy>=1.20.0 in /opt/conda/lib/python3.10/site-packages (from dask_ml) (1.24.3)\r\nRequirement already satisfied: pandas>=0.24.2 in /opt/conda/lib/python3.10/site-packages (from dask_ml) (2.0.3)\r\nRequirement already satisfied: scikit-learn>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from dask_ml) (1.2.2)\r\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from dask_ml) (1.11.3)\r\nCollecting dask-glm>=0.2.0 (from dask_ml)\r\n  Obtaining dependency information for dask-glm>=0.2.0 from https://files.pythonhosted.org/packages/8a/8e/cd1502dd2d00d54fb3e10880d4c8cb6699320a239da7a39c9f55044afdee/dask_glm-0.3.2-py2.py3-none-any.whl.metadata\r\n  Downloading dask_glm-0.3.2-py2.py3-none-any.whl.metadata (1.5 kB)\r\nRequirement already satisfied: multipledispatch>=0.4.9 in /opt/conda/lib/python3.10/site-packages (from dask_ml) (1.0.0)\r\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from dask_ml) (21.3)\r\nRequirement already satisfied: cloudpickle>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from dask-glm>=0.2.0->dask_ml) (2.2.1)\r\nCollecting sparse>=0.7.0 (from dask-glm>=0.2.0->dask_ml)\r\n  Downloading sparse-0.14.0-py2.py3-none-any.whl (80 kB)\r\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.0/81.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hRequirement already satisfied: click>=8.1 in /opt/conda/lib/python3.10/site-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (8.1.7)\r\nRequirement already satisfied: fsspec>=2021.09.0 in /opt/conda/lib/python3.10/site-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (2023.10.0)\r\nRequirement already satisfied: partd>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (1.4.1)\r\nRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (6.0.1)\r\nRequirement already satisfied: toolz>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (0.12.0)\r\nRequirement already satisfied: importlib-metadata>=4.13.0 in /opt/conda/lib/python3.10/site-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (6.8.0)\r\nRequirement already satisfied: jinja2>=2.10.3 in /opt/conda/lib/python3.10/site-packages (from distributed>=2.4.0->dask_ml) (3.1.2)\r\nRequirement already satisfied: locket>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from distributed>=2.4.0->dask_ml) (1.0.0)\r\nRequirement already satisfied: msgpack>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from distributed>=2.4.0->dask_ml) (1.0.5)\r\nRequirement already satisfied: psutil>=5.7.2 in /opt/conda/lib/python3.10/site-packages (from distributed>=2.4.0->dask_ml) (5.9.3)\r\nRequirement already satisfied: sortedcontainers>=2.0.5 in /opt/conda/lib/python3.10/site-packages (from distributed>=2.4.0->dask_ml) (2.4.0)\r\nRequirement already satisfied: tblib>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from distributed>=2.4.0->dask_ml) (2.0.0)\r\nRequirement already satisfied: tornado>=6.0.4 in /opt/conda/lib/python3.10/site-packages (from distributed>=2.4.0->dask_ml) (6.3.3)\r\nRequirement already satisfied: urllib3>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from distributed>=2.4.0->dask_ml) (1.26.15)\r\nRequirement already satisfied: zict>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from distributed>=2.4.0->dask_ml) (3.0.0)\r\nRequirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.0->dask_ml) (0.40.1)\r\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->dask_ml) (3.0.9)\r\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24.2->dask_ml) (2.8.2)\r\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24.2->dask_ml) (2023.3)\r\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24.2->dask_ml) (2023.3)\r\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.2.0->dask_ml) (1.3.2)\r\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.2.0->dask_ml) (3.2.0)\r\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=4.13.0->dask[array,dataframe]>=2.4.0->dask_ml) (3.16.2)\r\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=2.10.3->distributed>=2.4.0->dask_ml) (2.1.3)\r\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=0.24.2->dask_ml) (1.16.0)\r\nDownloading dask_glm-0.3.2-py2.py3-none-any.whl (13 kB)\r\nInstalling collected packages: sparse, dask-glm, dask_ml\r\nSuccessfully installed dask-glm-0.3.2 dask_ml-2023.3.24 sparse-0.14.0\r\n"
        }
      ],
      "execution_count": 8,
      "block_group": "5b444233fb4841f0b668d6fa9a2ed033"
    },
    {
      "cell_type": "code",
      "source": "# apply SN-filter (with p_unpaired calculation)\nfrom dask_ml.model_selection import train_test_split\ndf_sn = ddf[ddf[\"SN_filter\"]==1]\n\n# split into 2A3 MaP and DMS MaP datasets\ndf_2A3 = df_sn[df_sn[\"experiment_type\"]==\"2A3_MaP\"]\ndf_DMS = df_sn[df_sn[\"experiment_type\"]==\"DMS_MaP\"]\n\n# split into train and test\nX_2A3_seq = df_2A3[\"sequence\"]\nX_2A3_p_unpaired = df_2A3.loc[:, \"p_unp_1\":\"p_unp_206\"]\ny_2A3 = df_2A3.loc[:, df_2A3.columns.str.fullmatch(\"reactivity_\\d\\d\\d\\d\")]\nX_2A3_train_seq, X_2A3_test_seq, X_2A3_train_p_unpaired, X_2A3_test_p_unpaired, y_2A3_train, y_2A3_test = train_test_split(X_2A3_seq, X_2A3_p_unpaired, y_2A3, test_size=0.2, shuffle=True, blockwise=True, random_state=42)\nX_2A3_train_seq, X_2A3_validation_seq, X_2A3_train_p_unpaired, X_2A3_validation_p_unpaired, y_2A3_train, y_2A3_validation = train_test_split(X_2A3_train_seq, X_2A3_train_p_unpaired, y_2A3_train, test_size=0.25, shuffle=True, blockwise=True, random_state=42)\n\nX_DMS = df_DMS[\"sequence\"]\ny_DMS = df_DMS.loc[:, df_DMS.columns.str.fullmatch(\"reactivity_\\d\\d\\d\\d\")]\nX_DMS_train, X_DMS_test, y_DMS_train, y_DMS_test = train_test_split(X_DMS, y_DMS, test_size=0.2, shuffle=True, blockwise=True, random_state=42)\nX_DMS_train, X_DMS_validation, y_DMS_train, y_DMS_validation = train_test_split(X_DMS_train, y_DMS_train, test_size=0.25, shuffle=True, blockwise=True, random_state=42)",
      "metadata": {
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-12-17T04:22:26.081318Z",
          "iopub.status.idle": "2023-12-17T04:22:27.812069Z",
          "iopub.execute_input": "2023-12-17T04:22:26.082258Z",
          "shell.execute_reply": "2023-12-17T04:22:27.810813Z"
        },
        "papermill": {
          "status": "completed",
          "duration": 1.742288,
          "end_time": "2023-12-17T04:22:27.814527",
          "exception": false,
          "start_time": "2023-12-17T04:22:26.072239"
        },
        "cell_id": "d2216189ea8d4fb5b094a7ae89d04843",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 9,
      "block_group": "22a9e651095745dab0e7ba48230da300"
    },
    {
      "cell_type": "code",
      "source": "def df_toArray_train(ddf1A, ddf1B, ddf2): # for sequence, p_unpaired, and reactivity\n    with ProgressBar():\n        subset_columns = []\n        for i in range(206):\n            subset_columns.append(\"reactivity_0\"+str(i+1).zfill(3))\n\n        # Compute the subset of the Dask DataFrame and convert it to a Pandas DataFrame\n        reactivities = ddf2.compute().to_numpy()\n        p_unpaired = ddf1B.compute().to_numpy()\n\n        row_means = np.nanmean(reactivities, axis=1)\n\n        # Iterate over each element and replace NaN with the row mean\n        for i, row in enumerate(reactivities):\n            mask = np.isnan(row)\n            reactivities[i, mask] = row_means[i]\n\n        seqs = ddf1A.compute().tolist()\n\n        return seqs, p_unpaired, reactivities",
      "metadata": {
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-12-17T04:22:27.831475Z",
          "iopub.status.idle": "2023-12-17T04:22:27.838269Z",
          "iopub.execute_input": "2023-12-17T04:22:27.831780Z",
          "shell.execute_reply": "2023-12-17T04:22:27.837408Z"
        },
        "papermill": {
          "status": "completed",
          "duration": 0.017416,
          "end_time": "2023-12-17T04:22:27.840114",
          "exception": false,
          "start_time": "2023-12-17T04:22:27.822698"
        },
        "cell_id": "81acddcb6be147858b84479535348797",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 10,
      "block_group": "5d6a6a650ed14a4a9ed6b2053c59e448"
    },
    {
      "cell_type": "code",
      "source": "def df_toArray_test(ddf1A, ddf1B, ddf2): # for sequence, p_unpaired, and reactivity\n    with ProgressBar():\n        subset_columns = []\n        for i in range(206):\n            subset_columns.append(\"reactivity_0\"+str(i+1).zfill(3))\n\n        # Compute the subset of the Dask DataFrame and convert it to a Pandas DataFrame\n        reactivities = ddf2.compute().to_numpy()\n        p_unpaired = ddf1B.compute().to_numpy()\n\n        row_means = np.nanmean(reactivities, axis=1)\n\n        seqs = ddf1A.compute().tolist()\n\n        return seqs, p_unpaired, reactivities",
      "metadata": {
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-12-17T04:22:27.856883Z",
          "iopub.status.idle": "2023-12-17T04:22:27.863145Z",
          "iopub.execute_input": "2023-12-17T04:22:27.857514Z",
          "shell.execute_reply": "2023-12-17T04:22:27.862280Z"
        },
        "papermill": {
          "status": "completed",
          "duration": 0.017139,
          "end_time": "2023-12-17T04:22:27.865016",
          "exception": false,
          "start_time": "2023-12-17T04:22:27.847877"
        },
        "cell_id": "c54abde9255642369a8bb1028891599c",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 11,
      "block_group": "7005a4b801384e6091c3620a0a0620bf"
    },
    {
      "cell_type": "code",
      "source": "# Using 2A3 Data - with p_unpaired\nseqs, p_unpaired, reactivities = df_toArray_train(X_2A3_train_seq, X_2A3_train_p_unpaired, y_2A3_train)\ntrain_dataset = BedPeaksDataset(seqs, p_unpaired, reactivities)\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=50, num_workers = 0)\n\nseqs, p_unpaired, reactivities = df_toArray_train(X_2A3_validation_seq, X_2A3_validation_p_unpaired, y_2A3_validation)\nvalidation_dataset = BedPeaksDataset(seqs, p_unpaired, reactivities)\nvalidation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=50, num_workers = 0)\n\nseqs, p_unpaired, reactivities = df_toArray_test(X_2A3_test_seq, X_2A3_test_p_unpaired, y_2A3_test)\ntest_dataset = BedPeaksDataset(seqs, p_unpaired, reactivities)\ntest_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=50, num_workers = 0)",
      "metadata": {
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-12-17T04:22:27.881532Z",
          "iopub.status.idle": "2023-12-17T04:37:30.040514Z",
          "iopub.execute_input": "2023-12-17T04:22:27.881800Z",
          "shell.execute_reply": "2023-12-17T04:37:30.039509Z"
        },
        "papermill": {
          "status": "completed",
          "duration": 902.169697,
          "end_time": "2023-12-17T04:37:30.042695",
          "exception": false,
          "start_time": "2023-12-17T04:22:27.872998"
        },
        "cell_id": "04b645af762042a4bd8fb451234cfd94",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "[########################################] | 100% Completed | 100.54 s\n[########################################] | 100% Completed | 107.36 s\n[########################################] | 100% Completed | 101.76 s\n[########################################] | 100% Completed | 103.49 s\n[########################################] | 100% Completed | 99.97 s\n[########################################] | 100% Completed | 100.03 s\n[########################################] | 100% Completed | 98.35 s\n[########################################] | 100% Completed | 93.56 s\n[########################################] | 100% Completed | 95.23 s\n"
        }
      ],
      "execution_count": 12,
      "block_group": "4767cf30a1d14ecd9d0d5f6a643dfa82"
    },
    {
      "cell_type": "code",
      "source": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as data\nimport math\nimport copy",
      "metadata": {
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-12-17T04:37:31.391281Z",
          "iopub.status.idle": "2023-12-17T04:37:31.395975Z",
          "iopub.execute_input": "2023-12-17T04:37:31.392017Z",
          "shell.execute_reply": "2023-12-17T04:37:31.395116Z"
        },
        "papermill": {
          "status": "completed",
          "duration": 0.681685,
          "end_time": "2023-12-17T04:37:31.397886",
          "exception": false,
          "start_time": "2023-12-17T04:37:30.716201"
        },
        "cell_id": "40db270787214d89a4257f0e1d236ba2",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 13,
      "block_group": "ec65afa03eaa4761a98cfbd5b65a19bd"
    },
    {
      "cell_type": "code",
      "source": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\n\nclass TransformerModel(nn.Module):\n    def __init__(self, input_dim=5, d_model=512, nhead=8, num_encoder_layers=6, num_decoder_layers=6, dim_feedforward=2048, n_output_channels=10, dropout=0.2):\n        super(TransformerModel, self).__init__()\n        self.input_dim = input_dim\n        # Embedding layers that will transform input to match d_model size\n        self.embedding = nn.Linear(input_dim, d_model)\n        self.target_embedding = nn.Linear(1, d_model)\n\n        # Positional Encoding\n        self.pos_encoder = PositionalEncoding(d_model, dropout)\n        self.pos_decoder = PositionalEncoding(d_model, dropout)\n\n        # Transformer Encoder\n        encoder_layers = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout)\n        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_encoder_layers)\n\n        # Transformer Decoder\n        decoder_layers = nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout)\n        self.transformer_decoder = nn.TransformerDecoder(decoder_layers, num_layers=num_decoder_layers)\n\n        # Decoder layer to bring the output to the desired n_output_channels\n        self.decoder = nn.Linear(d_model, n_output_channels)\n\n    def forward(self, src, tgt):\n        # Reshape input to [seq_len, batch_size, input_dim]\n        src = src.view(-1, src.size(0), 5)  # Reshaped to [src_seq_len, batch_size, input_dim]\n        tgt = tgt.view(-1, tgt.size(0), 1)  # Reshaped to [tgt_seq_len, batch_size, input_dim]\n        \n        # Pass through the embedding layers\n        src = self.embedding(src)\n        tgt = self.target_embedding(tgt)\n\n        # Add positional encoding\n        src = self.pos_encoder(src)\n        tgt = self.pos_decoder(tgt)\n\n        # Pass through the Transformer Encoder\n        memory = self.transformer_encoder(src)\n\n        # Pass through the Transformer Decoder\n        output = self.transformer_decoder(tgt, memory)\n\n        output = torch.mean(output, dim=0)  # Now the shape should be [batch_size, d_model]\n    \n        # Now reshape it to match the linear layer's input expectation\n        output = output.view(output.size(0), -1)  # Shape should be [batch_size, d_model]\n\n        # Pass through the decoder\n        output = self.decoder(output)  # This should work as expected now\n        return output\n\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, dropout=0.1, max_len=5000):\n        super(PositionalEncoding, self).__init__()\n        self.dropout = nn.Dropout(p=dropout)\n\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0).transpose(0, 1)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        x = x + self.pe[:x.size(0), :]\n        return self.dropout(x)\n",
      "metadata": {
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-12-17T04:37:32.803819Z",
          "iopub.status.idle": "2023-12-17T04:37:32.822299Z",
          "iopub.execute_input": "2023-12-17T04:37:32.804720Z",
          "shell.execute_reply": "2023-12-17T04:37:32.821258Z"
        },
        "papermill": {
          "status": "completed",
          "duration": 0.705037,
          "end_time": "2023-12-17T04:37:32.824562",
          "exception": false,
          "start_time": "2023-12-17T04:37:32.119525"
        },
        "cell_id": "57fba68c9bdc4d349ad57ba7c711ace3",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 14,
      "block_group": "43b69a4718614bed9067e45d0115e0ba"
    },
    {
      "cell_type": "code",
      "source": "# https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html\nimport timeit\ntransformer = TransformerModel(input_dim=5, d_model=256, nhead=4, num_encoder_layers=3, num_decoder_layers=3, dim_feedforward=1024, n_output_channels=206)\n\n# train model\ntransformer, train_losses, valid_losses = train_model(transformer, train_dataloader, validation_dataloader, lr = 0.001, weight_decay = 0)\ntorch.save(transformer.state_dict(), 'model.pth')\n\n# # load model\n# transformer.load_state_dict(torch.load(\"/kaggle/input/transformer-model-2a3/transformer_model.pth\"))\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# transformer.to(device)",
      "metadata": {
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-12-17T04:37:34.216030Z",
          "iopub.status.idle": "2023-12-17T05:50:30.226274Z",
          "iopub.execute_input": "2023-12-17T04:37:34.217046Z",
          "shell.execute_reply": "2023-12-17T05:50:30.225383Z"
        },
        "papermill": {
          "status": "completed",
          "duration": 4376.705461,
          "end_time": "2023-12-17T05:50:30.228839",
          "exception": false,
          "start_time": "2023-12-17T04:37:33.523378"
        },
        "cell_id": "810698341a6d48c4811de5f97941da86",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Epoch 1 took 339.00s. Train loss: 0.1787., Valid loss: 0.1788. Patience: 10\nEpoch 2 took 336.85s. Train loss: 0.1771., Valid loss: 0.1783. Patience: 10\nEpoch 3 took 337.53s. Train loss: 0.1769., Valid loss: 0.1782. Patience: 10\nEpoch 4 took 336.41s. Train loss: 0.1769., Valid loss: 0.1783. Patience: 9\nEpoch 5 took 336.33s. Train loss: 0.1768., Valid loss: 0.1783. Patience: 8\nEpoch 6 took 335.95s. Train loss: 0.1768., Valid loss: 0.1784. Patience: 7\nEpoch 7 took 335.99s. Train loss: 0.1768., Valid loss: 0.1785. Patience: 6\nEpoch 8 took 336.04s. Train loss: 0.1768., Valid loss: 0.1784. Patience: 5\nEpoch 9 took 335.91s. Train loss: 0.1768., Valid loss: 0.1785. Patience: 4\nEpoch 10 took 335.62s. Train loss: 0.1768., Valid loss: 0.1785. Patience: 3\nEpoch 11 took 335.60s. Train loss: 0.1768., Valid loss: 0.1784. Patience: 2\nEpoch 12 took 335.71s. Train loss: 0.1768., Valid loss: 0.1785. Patience: 1\n"
        }
      ],
      "execution_count": 15,
      "block_group": "761b34d3328b4261b2af7a7e56b45f37"
    },
    {
      "cell_type": "code",
      "source": "device = 'cuda'\noutputs = []\nexpected_padded = []\nexpected_nonpadded = []\ntransformer.eval()\n\nfor (x, y) in test_dataloader:  # iterate over batches\n    \n    # add y to expected_nonpadded\n    expected_nonpadded.append(y.float().numpy())\n    \n    # add padding to y\n    y_pad = y.clone()\n\n    # add padding to y\n    row_means = np.nanmean(y_pad, axis=1)\n    for i, row in enumerate(y_pad):\n        mask = np.isnan(row)\n        y_pad[i, mask] = row_means[i]\n        \n    # add y_pad to expected_padded\n    expected_padded.append(y_pad.float().numpy())\n    \n    if torch.cuda.is_available():\n        y_pad = y_pad.to(device).float()\n        x = x.to(device).float()\n\n    output = transformer(x.float(), y_pad.float()).squeeze()  # your awesome model here!\n\n    output_np = output.detach().cpu().numpy()\n    outputs.append(output_np)\n\n# Concatenate all the outputs and expected results\noutput_np = np.concatenate(outputs)\nexpected_pad_np = np.concatenate(expected_padded)\nexpected_nonpad_np = np.concatenate(expected_nonpadded)\n\nprint(output_np)\nprint(expected_pad_np)\nprint(expected_nonpad_np)\nprint(output_np.shape)\nprint(expected_pad_np.shape)\nprint(expected_nonpad_np.shape)\n\n# Clip the values to be between 0 and 1\noutput_np = output_np.clip(0, 1)\nexpected_pad_np = expected_pad_np.clip(0, 1)\nexpected_nonpad_np = expected_nonpad_np.clip(0, 1)\n\n# Calculate the Mean Absolute Error\nmae1_pad = np.nanmean(np.abs(output_np - expected_pad_np))\nmae1_nonpad = np.nanmean(np.abs(output_np - expected_nonpad_np))\nprint(mae1_pad)\nprint(mae1_nonpad)",
      "metadata": {
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-12-17T05:50:31.549243Z",
          "iopub.status.idle": "2023-12-17T05:51:07.551071Z",
          "iopub.execute_input": "2023-12-17T05:50:31.550133Z",
          "shell.execute_reply": "2023-12-17T05:51:07.550069Z"
        },
        "papermill": {
          "status": "completed",
          "duration": 37.383089,
          "end_time": "2023-12-17T05:51:08.278424",
          "exception": false,
          "start_time": "2023-12-17T05:50:30.895335"
        },
        "cell_id": "900b2444f832469489768ea79dfe0899",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "/tmp/ipykernel_26/1129831263.py:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1772.)\n  y_pad[i, mask] = row_means[i]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "[[0.43209782 0.44418663 0.4249778  ... 0.43316352 0.4301526  0.43532902]\n [0.43209726 0.4441871  0.42497742 ... 0.43316287 0.43015245 0.43533015]\n [0.4320985  0.4441861  0.42497802 ... 0.43316257 0.43015298 0.43532974]\n ...\n [0.4320859  0.44418937 0.42497274 ... 0.43316427 0.43015945 0.43533313]\n [0.43209854 0.44418657 0.4249777  ... 0.43316197 0.43015358 0.43532962]\n [0.4320985  0.44418755 0.42497745 ... 0.433163   0.4301523  0.4353308 ]]\n[[0.43326   0.43326   0.43326   ... 0.43326   0.43326   0.43326  ]\n [0.39229   0.39229   0.39229   ... 0.39229   0.39229   0.39229  ]\n [0.56442   0.56442   0.56442   ... 0.56442   0.56442   0.56442  ]\n ...\n [0.42745   0.42745   0.42745   ... 0.42745   0.42745   0.42745  ]\n [0.4861262 0.4861262 0.4861262 ... 0.4861262 0.4861262 0.4861262]\n [0.42485   0.42485   0.42485   ... 0.42485   0.42485   0.42485  ]]\n[[nan nan nan ... nan nan nan]\n [nan nan nan ... nan nan nan]\n [nan nan nan ... nan nan nan]\n ...\n [nan nan nan ... nan nan nan]\n [nan nan nan ... nan nan nan]\n [nan nan nan ... nan nan nan]]\n(43945, 206)\n(43945, 206)\n(43945, 206)\n0.1938606\n0.32332692\n"
        }
      ],
      "execution_count": 16,
      "block_group": "d7bb2b9bf5a54977a296523a0a6ba06f"
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=fe343e39-d2c0-4296-915d-091d9a42752d' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kaggle": {
      "language": "python",
      "sourceType": "notebook",
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 51294,
          "sourceType": "competition",
          "databundleVersionId": 6923401
        },
        {
          "sourceId": 7107692,
          "datasetId": 4097862,
          "sourceType": "datasetVersion"
        }
      ],
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "dockerImageVersionId": 30587
    },
    "deepnote": {},
    "papermill": {
      "version": "2.4.0",
      "duration": 5357.233317,
      "end_time": "2023-12-17T05:51:12.861573",
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-12-17T04:21:55.628256",
      "output_path": "__notebook__.ipynb",
      "default_parameters": {},
      "environment_variables": {}
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "file_extension": ".py",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "nbconvert_exporter": "python"
    },
    "deepnote_notebook_id": "d8731974e2b64e6bbeed02cc63df3d4b",
    "deepnote_execution_queue": []
  }
}