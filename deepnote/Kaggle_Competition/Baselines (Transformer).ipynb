{
  "cells": [
    {
      "cell_type": "code",
      "source": "# import the libraries\nimport numpy as np\nimport dask.dataframe as dd\nfrom dask.diagnostics import ProgressBar\nfrom itertools import product\nimport matplotlib.pyplot as plt\n# from fitter import Fitter, get_common_distributions, get_distributions",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-11-20T05:56:34.394636Z",
          "iopub.status.idle": "2023-11-20T05:56:35.990966Z",
          "iopub.execute_input": "2023-11-20T05:56:34.395045Z",
          "shell.execute_reply": "2023-11-20T05:56:35.989607Z",
          "shell.execute_reply.started": "2023-11-20T05:56:34.395013Z"
        },
        "cell_id": "ecd4211c6dee4103a4fda0b4bbca0ba9",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 1,
      "block_group": "070b3f27475f4ab291ae053025fc5cd2"
    },
    {
      "cell_type": "code",
      "source": "# import os\n\n# # Set CUDA_LAUNCH_BLOCKING environment variable for better error messages\n# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
      "metadata": {
        "cell_id": "4e689a646359486eacedf56451bfb8dd",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 2,
      "block_group": "45f32774266d4a89a008dc4d454c1286"
    },
    {
      "cell_type": "code",
      "source": "# import, shuffle, and see the data\nddf = dd.read_csv('D:/桌面/xiaoyiass/daima/train_data.csv')\nshfl_ddf = ddf.sample(frac = 1, random_state = 42)\nshfl_ddf.head()",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-11-20T05:56:35.992658Z",
          "iopub.status.idle": "2023-11-20T05:56:40.480390Z",
          "iopub.execute_input": "2023-11-20T05:56:35.993192Z",
          "shell.execute_reply": "2023-11-20T05:56:40.479619Z",
          "shell.execute_reply.started": "2023-11-20T05:56:35.993161Z"
        },
        "cell_id": "ff1bc75b7ae2425684f049d651a00324",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sequence_id</th>\n      <th>sequence</th>\n      <th>experiment_type</th>\n      <th>dataset_name</th>\n      <th>reads</th>\n      <th>signal_to_noise</th>\n      <th>SN_filter</th>\n      <th>reactivity_0001</th>\n      <th>reactivity_0002</th>\n      <th>reactivity_0003</th>\n      <th>...</th>\n      <th>reactivity_error_0197</th>\n      <th>reactivity_error_0198</th>\n      <th>reactivity_error_0199</th>\n      <th>reactivity_error_0200</th>\n      <th>reactivity_error_0201</th>\n      <th>reactivity_error_0202</th>\n      <th>reactivity_error_0203</th>\n      <th>reactivity_error_0204</th>\n      <th>reactivity_error_0205</th>\n      <th>reactivity_error_0206</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>25107</th>\n      <td>dfab8bf1dc9e</td>\n      <td>GGGAACGACUCGAGUAGAGUCGAAAAUGAACAAGUUGACGUUUCUC...</td>\n      <td>DMS_MaP</td>\n      <td>15k_DMS</td>\n      <td>1653</td>\n      <td>0.579</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>31189</th>\n      <td>f8fab44626b9</td>\n      <td>GGGAACGACUCGAGUAGAGUCGAAAACCAACACACUCCUUCCCCCC...</td>\n      <td>2A3_MaP</td>\n      <td>DasLabBigLib_OneMil_15K_REP_2A3</td>\n      <td>122</td>\n      <td>0.346</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>40167</th>\n      <td>2f4d8eb6a6f0</td>\n      <td>GGGAACGACUCGAGUAGAGUCGAAAAAGUUAUGUGCAUGUUGUAGA...</td>\n      <td>2A3_MaP</td>\n      <td>DasLabBigLib_OneMil_15K_REP_2A3</td>\n      <td>116</td>\n      <td>0.411</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>17066</th>\n      <td>cd15884cb67a</td>\n      <td>GGGAACGACUCGAGUAGAGUCGAAAAGUGGAGUUCCUGUUGUAGAU...</td>\n      <td>DMS_MaP</td>\n      <td>15k_DMS</td>\n      <td>738</td>\n      <td>0.606</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>31317</th>\n      <td>44af286d8277</td>\n      <td>GGGAACGACUCGAGUAGAGUCGAAAACUUAGAAGUGACAGGUGACA...</td>\n      <td>2A3_MaP</td>\n      <td>DasLabBigLib_OneMil_15K_REP_2A3</td>\n      <td>248</td>\n      <td>0.688</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 419 columns</p>\n</div>",
            "text/plain": "        sequence_id                                           sequence  \\\n25107  dfab8bf1dc9e  GGGAACGACUCGAGUAGAGUCGAAAAUGAACAAGUUGACGUUUCUC...   \n31189  f8fab44626b9  GGGAACGACUCGAGUAGAGUCGAAAACCAACACACUCCUUCCCCCC...   \n40167  2f4d8eb6a6f0  GGGAACGACUCGAGUAGAGUCGAAAAAGUUAUGUGCAUGUUGUAGA...   \n17066  cd15884cb67a  GGGAACGACUCGAGUAGAGUCGAAAAGUGGAGUUCCUGUUGUAGAU...   \n31317  44af286d8277  GGGAACGACUCGAGUAGAGUCGAAAACUUAGAAGUGACAGGUGACA...   \n\n      experiment_type                     dataset_name  reads  \\\n25107         DMS_MaP                          15k_DMS   1653   \n31189         2A3_MaP  DasLabBigLib_OneMil_15K_REP_2A3    122   \n40167         2A3_MaP  DasLabBigLib_OneMil_15K_REP_2A3    116   \n17066         DMS_MaP                          15k_DMS    738   \n31317         2A3_MaP  DasLabBigLib_OneMil_15K_REP_2A3    248   \n\n       signal_to_noise  SN_filter  reactivity_0001  reactivity_0002  \\\n25107            0.579          0              NaN              NaN   \n31189            0.346          0              NaN              NaN   \n40167            0.411          0              NaN              NaN   \n17066            0.606          0              NaN              NaN   \n31317            0.688          0              NaN              NaN   \n\n       reactivity_0003  ...  reactivity_error_0197  reactivity_error_0198  \\\n25107              NaN  ...                    NaN                    NaN   \n31189              NaN  ...                    NaN                    NaN   \n40167              NaN  ...                    NaN                    NaN   \n17066              NaN  ...                    NaN                    NaN   \n31317              NaN  ...                    NaN                    NaN   \n\n       reactivity_error_0199  reactivity_error_0200  reactivity_error_0201  \\\n25107                    NaN                    NaN                    NaN   \n31189                    NaN                    NaN                    NaN   \n40167                    NaN                    NaN                    NaN   \n17066                    NaN                    NaN                    NaN   \n31317                    NaN                    NaN                    NaN   \n\n       reactivity_error_0202  reactivity_error_0203  reactivity_error_0204  \\\n25107                    NaN                    NaN                    NaN   \n31189                    NaN                    NaN                    NaN   \n40167                    NaN                    NaN                    NaN   \n17066                    NaN                    NaN                    NaN   \n31317                    NaN                    NaN                    NaN   \n\n       reactivity_error_0205  reactivity_error_0206  \n25107                    NaN                    NaN  \n31189                    NaN                    NaN  \n40167                    NaN                    NaN  \n17066                    NaN                    NaN  \n31317                    NaN                    NaN  \n\n[5 rows x 419 columns]"
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 3,
      "block_group": "48d7cbcbdbb6450ab798ad2038aef597"
    },
    {
      "cell_type": "code",
      "source": "dms_ddf = ddf.loc[ddf['experiment_type'] == \"DMS_MaP\"]\ntwoa3_ddf = ddf.loc[ddf['experiment_type'] == \"2A3_MaP\"]\ndms_ddf.head()",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-11-20T05:56:40.481764Z",
          "iopub.status.idle": "2023-11-20T05:56:42.832432Z",
          "iopub.execute_input": "2023-11-20T05:56:40.482272Z",
          "shell.execute_reply": "2023-11-20T05:56:42.831735Z",
          "shell.execute_reply.started": "2023-11-20T05:56:40.482244Z"
        },
        "cell_id": "1a2519b350234ae2a6702dcc00e5e5dd",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sequence_id</th>\n      <th>sequence</th>\n      <th>experiment_type</th>\n      <th>dataset_name</th>\n      <th>reads</th>\n      <th>signal_to_noise</th>\n      <th>SN_filter</th>\n      <th>reactivity_0001</th>\n      <th>reactivity_0002</th>\n      <th>reactivity_0003</th>\n      <th>...</th>\n      <th>reactivity_error_0197</th>\n      <th>reactivity_error_0198</th>\n      <th>reactivity_error_0199</th>\n      <th>reactivity_error_0200</th>\n      <th>reactivity_error_0201</th>\n      <th>reactivity_error_0202</th>\n      <th>reactivity_error_0203</th>\n      <th>reactivity_error_0204</th>\n      <th>reactivity_error_0205</th>\n      <th>reactivity_error_0206</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15000</th>\n      <td>8cdfeef009ea</td>\n      <td>GGGAACGACUCGAGUAGAGUCGAAAAACGUUGAUAUGGAUUUACUC...</td>\n      <td>DMS_MaP</td>\n      <td>15k_DMS</td>\n      <td>1668</td>\n      <td>0.972</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>15001</th>\n      <td>51e61fbde94d</td>\n      <td>GGGAACGACUCGAGUAGAGUCGAAAAACAUUGAUAUGGAUUUACUC...</td>\n      <td>DMS_MaP</td>\n      <td>15k_DMS</td>\n      <td>2421</td>\n      <td>0.167</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>15002</th>\n      <td>25ce8d5109cd</td>\n      <td>GGGAACGACUCGAGUAGAGUCGAAAAACCUUGAUAUGGAUUUACUC...</td>\n      <td>DMS_MaP</td>\n      <td>15k_DMS</td>\n      <td>1964</td>\n      <td>1.848</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>15003</th>\n      <td>07dcfb6d1965</td>\n      <td>GGGAACGACUCGAGUAGAGUCGAAAAACUUUGAUAUGGAUUUACUC...</td>\n      <td>DMS_MaP</td>\n      <td>15k_DMS</td>\n      <td>45863</td>\n      <td>9.291</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>15004</th>\n      <td>e561cc042a4c</td>\n      <td>GGGAACGACUCGAGUAGAGUCGAAAAACGAUGAUAUGGAUUUACUC...</td>\n      <td>DMS_MaP</td>\n      <td>15k_DMS</td>\n      <td>6219</td>\n      <td>3.210</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 419 columns</p>\n</div>",
            "text/plain": "        sequence_id                                           sequence  \\\n15000  8cdfeef009ea  GGGAACGACUCGAGUAGAGUCGAAAAACGUUGAUAUGGAUUUACUC...   \n15001  51e61fbde94d  GGGAACGACUCGAGUAGAGUCGAAAAACAUUGAUAUGGAUUUACUC...   \n15002  25ce8d5109cd  GGGAACGACUCGAGUAGAGUCGAAAAACCUUGAUAUGGAUUUACUC...   \n15003  07dcfb6d1965  GGGAACGACUCGAGUAGAGUCGAAAAACUUUGAUAUGGAUUUACUC...   \n15004  e561cc042a4c  GGGAACGACUCGAGUAGAGUCGAAAAACGAUGAUAUGGAUUUACUC...   \n\n      experiment_type dataset_name  reads  signal_to_noise  SN_filter  \\\n15000         DMS_MaP      15k_DMS   1668            0.972          0   \n15001         DMS_MaP      15k_DMS   2421            0.167          0   \n15002         DMS_MaP      15k_DMS   1964            1.848          1   \n15003         DMS_MaP      15k_DMS  45863            9.291          1   \n15004         DMS_MaP      15k_DMS   6219            3.210          1   \n\n       reactivity_0001  reactivity_0002  reactivity_0003  ...  \\\n15000              NaN              NaN              NaN  ...   \n15001              NaN              NaN              NaN  ...   \n15002              NaN              NaN              NaN  ...   \n15003              NaN              NaN              NaN  ...   \n15004              NaN              NaN              NaN  ...   \n\n       reactivity_error_0197  reactivity_error_0198  reactivity_error_0199  \\\n15000                    NaN                    NaN                    NaN   \n15001                    NaN                    NaN                    NaN   \n15002                    NaN                    NaN                    NaN   \n15003                    NaN                    NaN                    NaN   \n15004                    NaN                    NaN                    NaN   \n\n       reactivity_error_0200  reactivity_error_0201  reactivity_error_0202  \\\n15000                    NaN                    NaN                    NaN   \n15001                    NaN                    NaN                    NaN   \n15002                    NaN                    NaN                    NaN   \n15003                    NaN                    NaN                    NaN   \n15004                    NaN                    NaN                    NaN   \n\n       reactivity_error_0203  reactivity_error_0204  reactivity_error_0205  \\\n15000                    NaN                    NaN                    NaN   \n15001                    NaN                    NaN                    NaN   \n15002                    NaN                    NaN                    NaN   \n15003                    NaN                    NaN                    NaN   \n15004                    NaN                    NaN                    NaN   \n\n       reactivity_error_0206  \n15000                    NaN  \n15001                    NaN  \n15002                    NaN  \n15003                    NaN  \n15004                    NaN  \n\n[5 rows x 419 columns]"
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 4,
      "block_group": "a69d99e09e0b48a4a4267f2c820ee7c7"
    },
    {
      "cell_type": "code",
      "source": "# Get the shape of the Dask DataFrame\nshape = dms_ddf.shape\n\n# Extract the number of rows and columns from the shape tuple\nnum_rows, num_columns = shape[0].compute(), shape[1]\n\n# Print the size of the Dask DataFrame\nprint(f\"Number of Rows: {num_rows}\")\nprint(f\"Number of Columns: {num_columns}\")",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-11-20T05:56:42.834378Z",
          "iopub.status.idle": "2023-11-20T05:57:40.581474Z",
          "iopub.execute_input": "2023-11-20T05:56:42.834869Z",
          "shell.execute_reply": "2023-11-20T05:57:40.580028Z",
          "shell.execute_reply.started": "2023-11-20T05:56:42.834842Z"
        },
        "cell_id": "51ce94db7e2d430a93ff42cb45ecce6b",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Number of Rows: 821840\nNumber of Columns: 419\n"
        }
      ],
      "execution_count": 5,
      "block_group": "ba69b997e9984253a7cc9775dc4660ee"
    },
    {
      "cell_type": "code",
      "source": "bases={'A':0, 'C':1, 'G':2, 'T':3 }\n\ndef one_hot(string):\n\n    res = np.zeros((5, 206),\n                   dtype=np.float32)\n\n    for j in range(len(string)):\n        if string[j] in bases: # bases can be 'N' signifying missing: this corresponds to all 0 in the encoding\n            res[ bases[ string[j] ], j ]= 1.\n    for j in range(len(string),206):\n        res[4, j]= 1.\n    return res\n# one_hot(seqs[0])",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-11-20T05:57:40.583131Z",
          "iopub.status.idle": "2023-11-20T05:57:40.591144Z",
          "iopub.execute_input": "2023-11-20T05:57:40.583441Z",
          "shell.execute_reply": "2023-11-20T05:57:40.590143Z",
          "shell.execute_reply.started": "2023-11-20T05:57:40.583414Z"
        },
        "cell_id": "1c47b74d1dca45dea0de2050a9d9900b",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 6,
      "block_group": "08ddbf389f0c4be99661692402ed613b"
    },
    {
      "cell_type": "code",
      "source": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass BedPeaksDataset(torch.utils.data.IterableDataset):\n\n    def __init__(self, seq, reactivities):\n        super(BedPeaksDataset, self).__init__()\n        self.seq = seq\n        self.reactivities = reactivities\n\n    def __iter__(self):\n        for i in range(len(self.seq)):\n            yield(one_hot(self.seq[i]), self.reactivities[i]) # positive example\n\n# train_dataset = BedPeaksDataset(seqs, reactivities)\n# train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=10, num_workers = 0)",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-11-20T05:57:40.592411Z",
          "iopub.status.idle": "2023-11-20T05:57:42.285146Z",
          "iopub.execute_input": "2023-11-20T05:57:40.593113Z",
          "shell.execute_reply": "2023-11-20T05:57:42.283938Z",
          "shell.execute_reply.started": "2023-11-20T05:57:40.593085Z"
        },
        "cell_id": "d35ee22aa396497fa71024d0e01c70ab",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 7,
      "block_group": "c0a6bfa97ec7416eb4caa663a7ef75f9"
    },
    {
      "cell_type": "code",
      "source": "def run_one_epoch(train_flag, dataloader, cnn_1d, optimizer, device=\"cuda\"):\n\n    torch.set_grad_enabled(train_flag)\n    cnn_1d.train() if train_flag else cnn_1d.eval()\n\n    losses = []\n    accuracies = []\n\n    for (x,y) in dataloader: # collection of tuples with iterator\n        x = x.float()\n        y = y.float()\n        (x, y) = ( x.to(device), y.to(device) ) # transfer data to GPU\n\n        output = cnn_1d(x,y) # forward pass\n        output = output.squeeze() # remove spurious channel dimension\n        loss = F.mse_loss(output, y).float()\n\n        if train_flag:\n            loss.backward() # back propagation\n            optimizer.step()\n            optimizer.zero_grad()\n\n        losses.append(loss.detach().cpu().numpy())\n        # accuracy = torch.mean( ( (output > 0.0) == (y > 0.5) ).float() ) # output is in logit space so threshold is 0.\n        # accuracies.append(accuracy.detach().cpu().numpy())\n\n    return( np.mean(losses))",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-11-20T05:57:42.318579Z",
          "iopub.status.idle": "2023-11-20T05:57:42.330227Z",
          "iopub.execute_input": "2023-11-20T05:57:42.318969Z",
          "shell.execute_reply": "2023-11-20T05:57:42.329016Z",
          "shell.execute_reply.started": "2023-11-20T05:57:42.318934Z"
        },
        "cell_id": "497ff1031fe14eb1adad791601fec7f3",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 8,
      "block_group": "80467f102c1a4c3e9347234b9c16fd65"
    },
    {
      "cell_type": "code",
      "source": "# F.mse_loss(torch.tensor([5., 5., 5.]), torch.tensor([6., 6., 6.]))",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-11-20T01:17:04.505230Z",
          "iopub.status.idle": "2023-11-20T01:17:04.517953Z",
          "iopub.execute_input": "2023-11-20T01:17:04.505775Z",
          "shell.execute_reply": "2023-11-20T01:17:04.516493Z",
          "shell.execute_reply.started": "2023-11-20T01:17:04.505730Z"
        },
        "cell_id": "5e335e04af2c4ef38f44d5e17f5c33a9",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 9,
      "block_group": "f79549bdd5b14185abea522d1f0393b4"
    },
    {
      "cell_type": "code",
      "source": "def train_model(cnn_1d, train_dataloader, test_dataloader, epochs=100, patience=10, verbose = True, lr = 0.001, weight_decay = 0):\n    \"\"\"\n    Train a 1D CNN model and record accuracy metrics.\n    \"\"\"\n    # Move the model to the GPU here to make it runs there, and set \"device\" as above\n    # TODO CODE\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    cnn_1d.to(device)\n\n    # 1. Make new BedPeakDataset and DataLoader objects for both training and validation data.\n    # TODO CODE\n#     train_dataset = BedPeaksDataset(train_data, genome, cnn_1d.seq_len)\n#     train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=10, num_workers = 0)\n    # validation_dataset = BedPeaksDataset(validation_data, genome, cnn_1d.seq_len)\n    # validation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=1000)\n\n    # 2. Instantiates an optimizer for the model.\n    # TODO CODE\n    optimizer = torch.optim.Adam(cnn_1d.parameters(), amsgrad=True, lr = lr, weight_decay = weight_decay)\n\n    # 3. Run the training loop with early stopping.\n    # TODO CODE\n    train_losses = []\n    test_losses = []\n    # patience_counter = patience\n    best_test_loss = np.inf\n    check_point_filename = 'cnn_1d_checkpoint.pt' # to save the best model fit to date\n    for epoch in range(epochs):\n        start_time = timeit.default_timer()\n        train_loss = run_one_epoch(True, train_dataloader, cnn_1d, optimizer, device)\n        test_loss = run_one_epoch(False, test_dataloader, cnn_1d, optimizer, device)\n        train_losses.append(train_loss)\n        test_losses.append(test_loss)\n        # train_accs.append(train_acc)\n        # val_accs.append(val_acc)\n        if test_loss < best_test_loss:\n            torch.save(cnn_1d.state_dict(), check_point_filename)\n            best_test_loss = test_loss\n            patience_counter = patience\n        else:\n            patience_counter -= 1\n            if patience_counter <= 0:\n                cnn_1d.load_state_dict(torch.load(check_point_filename)) # recover the best model so far\n                break\n        elapsed = float(timeit.default_timer() - start_time)\n        print(\"Epoch {} took {:.2f}s. Train loss: {:.4f}., Test loss: {:.4f}. Pariance: {}\".format(epoch+1, elapsed, train_loss, test_loss, patience))\n\n    # 4. Return the fitted model (not strictly necessary since this happens \"in place\"), train and validation accuracies.\n    # TODO CODE\n    return(cnn_1d, train_losses, test_losses)",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-11-20T05:57:52.552208Z",
          "iopub.status.idle": "2023-11-20T05:57:52.565548Z",
          "iopub.execute_input": "2023-11-20T05:57:52.552611Z",
          "shell.execute_reply": "2023-11-20T05:57:52.564224Z",
          "shell.execute_reply.started": "2023-11-20T05:57:52.552573Z"
        },
        "cell_id": "8d1cf6c33e9441058d8f64b4b0fab484",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 10,
      "block_group": "888064d047844ae8844a96e78e76d562"
    },
    {
      "cell_type": "code",
      "source": "! pip install dask_ml",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-11-20T05:57:57.322809Z",
          "iopub.status.idle": "2023-11-20T05:58:13.348459Z",
          "iopub.execute_input": "2023-11-20T05:57:57.323252Z",
          "shell.execute_reply": "2023-11-20T05:58:13.346748Z",
          "shell.execute_reply.started": "2023-11-20T05:57:57.323218Z"
        },
        "cell_id": "25e514e9f6344ca29542bd925e67a57c",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Looking in indexes: https://pypi.org/simple/\nRequirement already satisfied: dask_ml in c:\\python311\\lib\\site-packages (2023.3.24)\nRequirement already satisfied: dask[array,dataframe]>=2.4.0 in c:\\python311\\lib\\site-packages (from dask_ml) (2023.11.0)\nRequirement already satisfied: distributed>=2.4.0 in c:\\python311\\lib\\site-packages (from dask_ml) (2023.11.0)\nRequirement already satisfied: numba>=0.51.0 in c:\\python311\\lib\\site-packages (from dask_ml) (0.58.1)\nRequirement already satisfied: numpy>=1.20.0 in c:\\python311\\lib\\site-packages (from dask_ml) (1.24.3)\nRequirement already satisfied: pandas>=0.24.2 in c:\\python311\\lib\\site-packages (from dask_ml) (2.1.2)\nRequirement already satisfied: scikit-learn>=1.2.0 in c:\\python311\\lib\\site-packages (from dask_ml) (1.3.2)\nRequirement already satisfied: scipy in c:\\python311\\lib\\site-packages (from dask_ml) (1.11.3)\nRequirement already satisfied: dask-glm>=0.2.0 in c:\\python311\\lib\\site-packages (from dask_ml) (0.3.1)\nRequirement already satisfied: multipledispatch>=0.4.9 in c:\\python311\\lib\\site-packages (from dask_ml) (1.0.0)\nRequirement already satisfied: packaging in c:\\users\\woodo\\appdata\\roaming\\python\\python311\\site-packages (from dask_ml) (23.1)\nRequirement already satisfied: cloudpickle>=0.2.2 in c:\\python311\\lib\\site-packages (from dask-glm>=0.2.0->dask_ml) (3.0.0)\nRequirement already satisfied: sparse>=0.7.0 in c:\\python311\\lib\\site-packages (from dask-glm>=0.2.0->dask_ml) (0.14.0)\nRequirement already satisfied: click>=8.1 in c:\\python311\\lib\\site-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (8.1.7)\nRequirement already satisfied: fsspec>=2021.09.0 in c:\\python311\\lib\\site-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (2023.4.0)\nRequirement already satisfied: partd>=1.2.0 in c:\\python311\\lib\\site-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (1.4.1)\nRequirement already satisfied: pyyaml>=5.3.1 in c:\\python311\\lib\\site-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (6.0.1)\nRequirement already satisfied: toolz>=0.10.0 in c:\\python311\\lib\\site-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (0.12.0)\nRequirement already satisfied: importlib-metadata>=4.13.0 in c:\\python311\\lib\\site-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (6.8.0)\nRequirement already satisfied: jinja2>=2.10.3 in c:\\users\\woodo\\appdata\\roaming\\python\\python311\\site-packages (from distributed>=2.4.0->dask_ml) (3.1.2)\nRequirement already satisfied: locket>=1.0.0 in c:\\python311\\lib\\site-packages (from distributed>=2.4.0->dask_ml) (1.0.0)\nRequirement already satisfied: msgpack>=1.0.0 in c:\\python311\\lib\\site-packages (from distributed>=2.4.0->dask_ml) (1.0.7)\nRequirement already satisfied: psutil>=5.7.2 in c:\\users\\woodo\\appdata\\roaming\\python\\python311\\site-packages (from distributed>=2.4.0->dask_ml) (5.9.5)\nRequirement already satisfied: sortedcontainers>=2.0.5 in c:\\python311\\lib\\site-packages (from distributed>=2.4.0->dask_ml) (2.4.0)\nRequirement already satisfied: tblib>=1.6.0 in c:\\python311\\lib\\site-packages (from distributed>=2.4.0->dask_ml) (3.0.0)\nRequirement already satisfied: tornado>=6.0.4 in c:\\users\\woodo\\appdata\\roaming\\python\\python311\\site-packages (from distributed>=2.4.0->dask_ml) (6.3.2)\nRequirement already satisfied: urllib3>=1.24.3 in c:\\python311\\lib\\site-packages (from distributed>=2.4.0->dask_ml) (2.0.5)\nRequirement already satisfied: zict>=3.0.0 in c:\\python311\\lib\\site-packages (from distributed>=2.4.0->dask_ml) (3.0.0)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in c:\\python311\\lib\\site-packages (from numba>=0.51.0->dask_ml) (0.41.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\woodo\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=0.24.2->dask_ml) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in c:\\python311\\lib\\site-packages (from pandas>=0.24.2->dask_ml) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in c:\\python311\\lib\\site-packages (from pandas>=0.24.2->dask_ml) (2023.3)\nRequirement already satisfied: joblib>=1.1.1 in c:\\python311\\lib\\site-packages (from scikit-learn>=1.2.0->dask_ml) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in c:\\python311\\lib\\site-packages (from scikit-learn>=1.2.0->dask_ml) (3.2.0)\nRequirement already satisfied: colorama in c:\\users\\woodo\\appdata\\roaming\\python\\python311\\site-packages (from click>=8.1->dask[array,dataframe]>=2.4.0->dask_ml) (0.4.6)\nRequirement already satisfied: zipp>=0.5 in c:\\python311\\lib\\site-packages (from importlib-metadata>=4.13.0->dask[array,dataframe]>=2.4.0->dask_ml) (3.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in c:\\users\\woodo\\appdata\\roaming\\python\\python311\\site-packages (from jinja2>=2.10.3->distributed>=2.4.0->dask_ml) (2.1.3)\nRequirement already satisfied: six>=1.5 in c:\\users\\woodo\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas>=0.24.2->dask_ml) (1.16.0)\n"
        }
      ],
      "execution_count": 11,
      "block_group": "ec8d63b8c38848c99b06646406e6504d"
    },
    {
      "cell_type": "code",
      "source": "# apply SN-filter\nfrom dask_ml.model_selection import train_test_split\ndf_sn = ddf[ddf[\"SN_filter\"]==1]\n\n# split into 2A3 MaP and DMS MaP datasets\ndf_2A3 = df_sn[df_sn[\"experiment_type\"]==\"2A3_MaP\"]\ndf_DMS = df_sn[df_sn[\"experiment_type\"]==\"DMS_MaP\"]\n\n# split into train and test\nX_2A3 = df_2A3[\"sequence\"]\ny_2A3 = df_2A3.loc[:, df_2A3.columns.str.fullmatch(\"reactivity_\\d\\d\\d\\d\")]\nX_2A3_train, X_2A3_test, y_2A3_train, y_2A3_test = train_test_split(X_2A3, y_2A3, test_size=0.2, shuffle=True, blockwise=True, random_state=42)\n\nX_DMS = df_DMS[\"sequence\"]\ny_DMS = df_DMS.loc[:, df_DMS.columns.str.fullmatch(\"reactivity_\\d\\d\\d\\d\")]\nX_DMS_train, X_DMS_test, y_DMS_train, y_DMS_test = train_test_split(X_DMS, y_DMS, test_size=0.2, shuffle=True, blockwise=True, random_state=42)",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-11-20T05:58:13.351680Z",
          "iopub.status.idle": "2023-11-20T05:58:14.750930Z",
          "iopub.execute_input": "2023-11-20T05:58:13.352164Z",
          "shell.execute_reply": "2023-11-20T05:58:14.749946Z",
          "shell.execute_reply.started": "2023-11-20T05:58:13.352118Z"
        },
        "cell_id": "ee93f013f3bb4f57a2880d1f02bb80e8",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 12,
      "block_group": "968dd0224b6b4bbca1bfbb5003254cda"
    },
    {
      "cell_type": "code",
      "source": "def df_toArray(ddf1, ddf2):\n    subset_columns = []\n    for i in range(206):\n        subset_columns.append(\"reactivity_0\"+str(i+1).zfill(3))\n\n    # Use .to_dask_array() to convert the subset of the DataFrame to a Dask Array\n    # subset = small_set[subset_columns]\n\n    # Compute the subset of the Dask DataFrame and convert it to a Pandas DataFrame\n    reactivities = ddf2.compute().to_numpy()\n\n    row_means = np.nanmean(reactivities, axis=1)\n\n    # Iterate over each element and replace NaN with the row mean\n    for i, row in enumerate(reactivities):\n        mask = np.isnan(row)\n        reactivities[i, mask] = row_means[i]\n\n    reactivities\n\n    seqs = ddf1.compute().tolist()\n    return seqs, reactivities\n    \n# df_toArray(X_2A3_train, y_2A3_train)",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-11-20T05:58:14.752286Z",
          "iopub.status.idle": "2023-11-20T05:58:14.760162Z",
          "iopub.execute_input": "2023-11-20T05:58:14.752589Z",
          "shell.execute_reply": "2023-11-20T05:58:14.759199Z",
          "shell.execute_reply.started": "2023-11-20T05:58:14.752563Z"
        },
        "cell_id": "8c067108ef204bcf93598ada695f4974",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 13,
      "block_group": "00194e19c8b949c4a37980bd0971a21d"
    },
    {
      "cell_type": "code",
      "source": "seqs, reactivities = df_toArray(X_2A3_train, y_2A3_train)\ntrain_dataset = BedPeaksDataset(seqs, reactivities)\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=100, num_workers = 0)\n\nseqs, reactivities = df_toArray(X_2A3_test, y_2A3_test)\ntest_dataset = BedPeaksDataset(seqs, reactivities)\ntest_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=100, num_workers = 0)",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-11-20T05:58:14.761990Z",
          "iopub.status.idle": "2023-11-20T06:01:48.101797Z",
          "iopub.execute_input": "2023-11-20T05:58:14.762507Z",
          "shell.execute_reply": "2023-11-20T06:01:48.100847Z",
          "shell.execute_reply.started": "2023-11-20T05:58:14.762478Z"
        },
        "cell_id": "3b97ed4e72d24551a9af9d75937a32cc",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 14,
      "block_group": "52eeee4f3f27474da6fb7a6869465f9a"
    },
    {
      "cell_type": "code",
      "source": "# import timeit\n# my_cnn1d_1 = CNN_1d()\n# # print(my_cnn1d.seq_le\n# my_cnn1d_1 = my_cnn1d_1.float()\n# my_cnn1d_1, train_losses, test_losses = train_model(my_cnn1d_1, train_dataloader, test_dataloader, lr = 0.001, weight_decay = 0)",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-11-20T01:21:38.921383Z",
          "iopub.status.idle": "2023-11-20T01:21:38.944373Z",
          "iopub.execute_input": "2023-11-20T01:21:38.925079Z",
          "shell.execute_reply": "2023-11-20T01:21:38.939838Z",
          "shell.execute_reply.started": "2023-11-20T01:21:38.924880Z"
        },
        "cell_id": "4b391b112b964b1eb0cd0db286cb5e1d",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 15,
      "block_group": "43fde28989b54dbb88a048b09e2da997"
    },
    {
      "cell_type": "code",
      "source": "# device = 'cuda'\n# outputs = []\n# expected = []\n# for (x,y) in train_dataloader: # iterate over batches\n#     # print(y)\n#     if torch.cuda.is_available():\n#         x = x.to(device)\n#     output = my_cnn1d_1(x).squeeze() # your awesome model here!\n#     output = torch.sigmoid(output)\n#     output_np = output.detach().cpu().numpy()\n#     outputs.append(output_np)\n#     expected.append(y.numpy())\n# output_np = np.concatenate(outputs)\n# expected_np = np.concatenate(expected)\n\n# print(output_np)\n# print(expected_np)\n\n# output_np = output_np.clip(0, 1)\n# expected_np = expected_np.clip(0,1)\n\n# mae1 = np.mean(np.abs(output_np - expected_np))\n# mae1",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-11-20T01:21:38.949379Z",
          "iopub.status.idle": "2023-11-20T01:21:38.970603Z",
          "iopub.execute_input": "2023-11-20T01:21:38.950369Z",
          "shell.execute_reply": "2023-11-20T01:21:38.966588Z",
          "shell.execute_reply.started": "2023-11-20T01:21:38.950242Z"
        },
        "cell_id": "e654cd17fc3647e1a042c8da42eee4de",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 16,
      "block_group": "3a0c5b251189418c91afa377e0dcf5a8"
    },
    {
      "cell_type": "code",
      "source": "# seqs, reactivities = df_toArray(X_DMS_train, y_DMS_train)\n# train_dataset = BedPeaksDataset(seqs, reactivities)\n# train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=1000, num_workers = 0)\n\n# seqs, reactivities = df_toArray(X_DMS_test, y_DMS_train)\n# test_dataset = BedPeaksDataset(seqs, reactivities)\n# test_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=1000, num_workers = 0)\n\n# my_cnn1d_2 = CNN_1d()\n# # print(my_cnn1d.seq_le\n# my_cnn1d_2 = my_cnn1d_2.float()\n# my_cnn1d_2, train_losses, test_losses = train_model(my_cnn1d_2, train_dataloader, test_dataloader, lr = 0.001, weight_decay = 0)",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-11-20T01:21:38.975508Z",
          "iopub.status.idle": "2023-11-20T01:21:38.993045Z",
          "iopub.execute_input": "2023-11-20T01:21:38.977941Z",
          "shell.execute_reply": "2023-11-20T01:21:38.989832Z",
          "shell.execute_reply.started": "2023-11-20T01:21:38.977830Z"
        },
        "cell_id": "8fe0d4eb687f45918833b380bb33e191",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 17,
      "block_group": "3841412748944109852add5349f81a06"
    },
    {
      "cell_type": "code",
      "source": "# device = 'cuda'\n# outputs = []\n# expected = []\n# for (x,y) in train_dataloader: # iterate over batches\n#     # print(y)\n#     if torch.cuda.is_available():\n#         x = x.to(device)\n#     output = my_cnn1d_2(x).squeeze() # your awesome model here!\n#     output = torch.sigmoid(output)\n#     output_np = output.detach().cpu().numpy()\n#     outputs.append(output_np)\n#     expected.append(y.numpy())\n# output_np = np.concatenate(outputs)\n# expected_np = np.concatenate(expected)\n\n# print(output_np)\n# print(expected_np)\n\n# output_np = output_np.clip(0, 1)\n# expected_np = expected_np.clip(0,1)\n\n# mae2 = np.mean(np.abs(output_np - expected_np))\n# mae2",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-11-20T01:21:38.998184Z",
          "iopub.status.idle": "2023-11-20T01:21:39.018596Z",
          "iopub.execute_input": "2023-11-20T01:21:38.999295Z",
          "shell.execute_reply": "2023-11-20T01:21:39.014596Z",
          "shell.execute_reply.started": "2023-11-20T01:21:38.999197Z"
        },
        "cell_id": "1766a440965f42e3a7ce3ca676fec749",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 18,
      "block_group": "b72c8dc380994e6da0e3b7435481e496"
    },
    {
      "cell_type": "code",
      "source": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as data\nimport math\nimport copy",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-11-20T06:01:48.103173Z",
          "iopub.status.idle": "2023-11-20T06:01:48.108590Z",
          "iopub.execute_input": "2023-11-20T06:01:48.103745Z",
          "shell.execute_reply": "2023-11-20T06:01:48.107459Z",
          "shell.execute_reply.started": "2023-11-20T06:01:48.103698Z"
        },
        "cell_id": "08f7a3dfb0f1458daf1c1d01c1490b8d",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 19,
      "block_group": "c8e494911a844b90b903e020ba2ad97b"
    },
    {
      "cell_type": "code",
      "source": "# import torch\n# import torch.nn as nn\n# import torch.nn.functional as F\n# import math\n# import copy\n\n# def clones(module, N):\n#     return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n\n# class TransformerModel(nn.Module):\n#     def __init__(self, input_dim=5, d_model=512, nhead=8, num_encoder_layers=6, dim_feedforward=2048, n_output_channels = 206, dropout=0.2):\n#         super(TransformerModel, self).__init__()\n\n#         # Embedding layer that will transform input to match d_model size\n#         self.embedding = nn.Linear(input_dim, d_model)\n\n#         # Positional Encoding\n#         self.pos_encoder = PositionalEncoding(d_model, dropout)\n\n#         # Transformer Encoder Layers\n#         self_attn = MultiHeadAttention(d_model, nhead)\n#         ff = PositionWiseFeedForward(d_model, 206)\n#         self.encoder_layers = clones(EncoderLayer(d_model, self_attn, ff, dropout), num_encoder_layers)\n#         self.norm = LayerNorm(d_model)\n\n#         # Decoder layer to bring the output to the desired n_output_channels\n#         self.decoder = nn.Linear(d_model * 206, n_output_channels)  # Adjust the multiplication factor as per your input sequence length\n\n#     def forward(self, src):\n#         # Reshape input to [batch_size, seq_len, input_dim]\n#         src = src.view(src.size(0), -1, 5)  # Assuming src has shape [batch_size, 5, 206]\n        \n#         # Pass through the embedding layer\n#         src = self.embedding(src)\n\n#         # Add positional encoding\n#         src = self.pos_encoder(src)\n\n#         # Pass through the Transformer Encoder\n#         for layer in self.encoder_layers:\n#             src = layer(src)\n\n#         src = self.norm(src)\n#         src = src.view(src.size(0), -1)\n\n#         # Pass through the decoder\n#         output = self.decoder(src)\n#         return output\n\n# class PositionalEncoding(nn.Module):\n#     def __init__(self, d_model, dropout=0.1, max_len=5000):\n#         super(PositionalEncoding, self).__init__()\n#         self.dropout = nn.Dropout(p=dropout)\n\n#         pe = torch.zeros(max_len, d_model)\n#         position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n#         div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n#         pe[:, 0::2] = torch.sin(position * div_term)\n#         pe[:, 1::2] = torch.cos(position * div_term)\n#         pe = pe.unsqueeze(0).transpose(0, 1)\n#         self.register_buffer('pe', pe)\n\n#     def forward(self, x):\n#         x = x + self.pe[:x.size(0), :]\n#         return self.dropout(x)\n\n# # ... Include the other classes such as LayerNorm, PositionalEncoding, MultiHeadedAttention, etc.\n\n# # Example instantiation of the model\n# # n_output_channels = 10  # Modify as needed\n# # transformer = TransformerModel(n_output_channels=n_output_channels)\n",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-11-20T01:38:52.040130Z",
          "iopub.status.idle": "2023-11-20T01:38:52.065695Z",
          "iopub.execute_input": "2023-11-20T01:38:52.040728Z",
          "shell.execute_reply": "2023-11-20T01:38:52.064268Z",
          "shell.execute_reply.started": "2023-11-20T01:38:52.040686Z"
        },
        "cell_id": "87a68c21d3ec4657b6954dd6dbe2a77d",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 20,
      "block_group": "44c091ee7aae49a3920d7942afcc44a3"
    },
    {
      "cell_type": "code",
      "source": "# import torch\n# import torch.nn as nn\n# import torch.nn.functional as F\n# import math\n\n# class TransformerModel(nn.Module):\n#     def __init__(self, input_dim=5, d_model=512, nhead=8, num_encoder_layers=6, dim_feedforward=2048, n_output_channels = 206, dropout=0.2):\n#         super(TransformerModel, self).__init__()\n\n#         # Embedding layer that will transform input to match d_model size\n#         self.embedding = nn.Linear(input_dim, d_model)\n\n#         # Positional Encoding\n#         self.pos_encoder = PositionalEncoding(d_model, dropout)\n\n#         # Transformer Encoder\n#         encoder_layers = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout)\n#         self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_encoder_layers)\n\n#         # Decoder layer to bring the output to the desired n_output_channels\n#         self.decoder = nn.Linear(d_model, n_output_channels)\n\n#     def forward(self, src):\n#         # Reshape input to [batch_size, seq_len, input_dim]\n#         src = src.view(src.size(0), -1, 5)  # Assuming src has shape [batch_size, 5, 206]\n        \n#         # Pass through the embedding layer\n#         src = self.embedding(src)\n\n#         # Add positional encoding\n#         src = self.pos_encoder(src)\n\n#         # Pass through the Transformer Encoder\n#         output = self.transformer_encoder(src)\n\n#         # Flatten the output for the linear layer\n#         output = output.view(output.size(0), -1)\n\n#         # Pass through the decoder\n#         output = self.decoder(output)\n#         return output\n\n# class PositionalEncoding(nn.Module):\n#     def __init__(self, d_model, dropout=0.1, max_len=5000):\n#         super(PositionalEncoding, self).__init__()\n#         self.dropout = nn.Dropout(p=dropout)\n\n#         pe = torch.zeros(max_len, d_model)\n#         position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n#         div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n#         pe[:, 0::2] = torch.sin(position * div_term)\n#         pe[:, 1::2] = torch.cos(position * div_term)\n#         pe = pe.unsqueeze(0).transpose(0, 1)\n#         self.register_buffer('pe', pe)\n\n#     def forward(self, x):\n#         x = x + self.pe[:x.size(0), :]\n#         return self.dropout(x)\n\n# # # Example instantiation of the model\n# # n_output_channels = 206  # Modify as needed\n# # transformer = TransformerModel(n_output_channels=n_output_channels)\n",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-11-20T01:43:20.459647Z",
          "iopub.status.idle": "2023-11-20T01:43:20.587097Z",
          "iopub.execute_input": "2023-11-20T01:43:20.460144Z",
          "shell.execute_reply": "2023-11-20T01:43:20.585722Z",
          "shell.execute_reply.started": "2023-11-20T01:43:20.460108Z"
        },
        "cell_id": "3387655def744d4da484a894cc909db1",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 21,
      "block_group": "1f957e1bf3484ef887c4a351dc2ce9f9"
    },
    {
      "cell_type": "code",
      "source": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\n\nclass TransformerModel(nn.Module):\n    def __init__(self, input_dim=5, d_model=512, nhead=8, num_encoder_layers=6, num_decoder_layers=6, dim_feedforward=2048, n_output_channels=10, dropout=0.2):\n        super(TransformerModel, self).__init__()\n        self.input_dim = input_dim\n        # Embedding layers that will transform input to match d_model size\n        self.embedding = nn.Linear(input_dim, d_model)\n        self.target_embedding = nn.Linear(1, d_model)\n\n        # Positional Encoding\n        self.pos_encoder = PositionalEncoding(d_model, dropout)\n        self.pos_decoder = PositionalEncoding(d_model, dropout)\n\n        # Transformer Encoder\n        encoder_layers = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout)\n        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_encoder_layers)\n\n        # Transformer Decoder\n        decoder_layers = nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout)\n        self.transformer_decoder = nn.TransformerDecoder(decoder_layers, num_layers=num_decoder_layers)\n\n        # Decoder layer to bring the output to the desired n_output_channels\n        self.decoder = nn.Linear(d_model, n_output_channels)\n\n    def forward(self, src, tgt):\n        # Reshape input to [seq_len, batch_size, input_dim]\n#         print(src.shape)\n#         print(tgt.shape)\n        src = src.view(-1, src.size(0), 5)  # Reshaped to [src_seq_len, batch_size, input_dim]\n        tgt = tgt.view(-1, tgt.size(0), 1)  # Reshaped to [tgt_seq_len, batch_size, input_dim]\n        \n        # Pass through the embedding layers\n        src = self.embedding(src)\n        tgt = self.target_embedding(tgt)\n\n        # Add positional encoding\n        src = self.pos_encoder(src)\n        tgt = self.pos_decoder(tgt)\n\n        # Pass through the Transformer Encoder\n        memory = self.transformer_encoder(src)\n\n        # Pass through the Transformer Decoder\n        output = self.transformer_decoder(tgt, memory)\n\n        output = torch.mean(output, dim=0)  # Now the shape should be [batch_size, d_model]\n    \n        # Now reshape it to match the linear layer's input expectation\n        output = output.view(output.size(0), -1)  # Shape should be [batch_size, d_model]\n\n        # Pass through the decoder\n        output = self.decoder(output)  # This should work as expected now\n#         print(output.shape)\n        return output\n\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, dropout=0.1, max_len=5000):\n        super(PositionalEncoding, self).__init__()\n        self.dropout = nn.Dropout(p=dropout)\n\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0).transpose(0, 1)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        x = x + self.pe[:x.size(0), :]\n        return self.dropout(x)\n\n# # Example instantiation of the model\n# n_output_channels = 10  # Modify as needed\n# transformer = TransformerModel(n_output_channels=n_output_channels)\n",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-11-20T06:21:08.707085Z",
          "iopub.status.idle": "2023-11-20T06:21:08.728090Z",
          "iopub.execute_input": "2023-11-20T06:21:08.707488Z",
          "shell.execute_reply": "2023-11-20T06:21:08.726796Z",
          "shell.execute_reply.started": "2023-11-20T06:21:08.707458Z"
        },
        "cell_id": "b8b1968a8f774fcd8efb11e1c7b72641",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 22,
      "block_group": "0f6bbe6b353647da94e62463b5c6d721"
    },
    {
      "cell_type": "code",
      "source": "import timeit\n# my_cnn1d_1 = CNN_1d()\n# print(my_cnn1d.seq_le\n# my_cnn1d_1 = my_cnn1d_1.float()\ntransformer = TransformerModel(input_dim= 5, d_model= 512, nhead= 8, num_encoder_layers = 2, dim_feedforward = 2048, n_output_channels = 206)\ntransformer, train_losses, test_losses = train_model(transformer, train_dataloader, test_dataloader, lr = 0.001, weight_decay = 0)",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2023-11-20T06:21:13.473431Z",
          "iopub.status.idle": "2023-11-20T06:21:29.893584Z",
          "iopub.execute_input": "2023-11-20T06:21:13.473876Z",
          "shell.execute_reply": "2023-11-20T06:21:29.891779Z",
          "shell.execute_reply.started": "2023-11-20T06:21:13.473842Z"
        },
        "cell_id": "e8a4c99dc89a476fad07d743363a8db6",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "c:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Epoch 1 took 384.68s. Train loss: 0.1732., Test loss: 0.1844. Pariance: 10\nEpoch 2 took 383.59s. Train loss: 0.1709., Test loss: 0.1841. Pariance: 10\nEpoch 3 took 383.66s. Train loss: 0.1707., Test loss: 0.1839. Pariance: 10\nEpoch 4 took 383.61s. Train loss: 0.1707., Test loss: 0.1839. Pariance: 10\nEpoch 5 took 375.41s. Train loss: 0.1708., Test loss: 0.1839. Pariance: 10\nEpoch 6 took 379.46s. Train loss: 0.1709., Test loss: 0.1840. Pariance: 10\nEpoch 7 took 383.76s. Train loss: 0.1709., Test loss: 0.1839. Pariance: 10\nEpoch 8 took 383.79s. Train loss: 0.1709., Test loss: 0.1839. Pariance: 10\nEpoch 9 took 383.70s. Train loss: 0.1710., Test loss: 0.1840. Pariance: 10\nEpoch 10 took 383.91s. Train loss: 0.1711., Test loss: 0.1840. Pariance: 10\nEpoch 11 took 383.87s. Train loss: 0.1711., Test loss: 0.1839. Pariance: 10\nEpoch 12 took 383.77s. Train loss: 0.1711., Test loss: 0.1838. Pariance: 10\n"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32md:\\桌面\\xiaoyiass\\daima\\fork-of-rna-folding-transformer (1).ipynb 单元格 23\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# my_cnn1d_1 = CNN_1d()\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# print(my_cnn1d.seq_le\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# my_cnn1d_1 = my_cnn1d_1.float()\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X31sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m transformer \u001b[39m=\u001b[39m TransformerModel(input_dim\u001b[39m=\u001b[39m \u001b[39m5\u001b[39m, d_model\u001b[39m=\u001b[39m \u001b[39m512\u001b[39m, nhead\u001b[39m=\u001b[39m \u001b[39m8\u001b[39m, num_encoder_layers \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m, dim_feedforward \u001b[39m=\u001b[39m \u001b[39m2048\u001b[39m, n_output_channels \u001b[39m=\u001b[39m \u001b[39m206\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X31sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m transformer, train_losses, test_losses \u001b[39m=\u001b[39m train_model(transformer, train_dataloader, test_dataloader, lr \u001b[39m=\u001b[39;49m \u001b[39m0.001\u001b[39;49m, weight_decay \u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m)\n",
            "\u001b[1;32md:\\桌面\\xiaoyiass\\daima\\fork-of-rna-folding-transformer (1).ipynb 单元格 23\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X31sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X31sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     start_time \u001b[39m=\u001b[39m timeit\u001b[39m.\u001b[39mdefault_timer()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X31sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     train_loss \u001b[39m=\u001b[39m run_one_epoch(\u001b[39mTrue\u001b[39;49;00m, train_dataloader, cnn_1d, optimizer, device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X31sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     test_loss \u001b[39m=\u001b[39m run_one_epoch(\u001b[39mFalse\u001b[39;00m, test_dataloader, cnn_1d, optimizer, device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X31sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     train_losses\u001b[39m.\u001b[39mappend(train_loss)\n",
            "\u001b[1;32md:\\桌面\\xiaoyiass\\daima\\fork-of-rna-folding-transformer (1).ipynb 单元格 23\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X31sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X31sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X31sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     losses\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39mnumpy())\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X31sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39m# accuracy = torch.mean( ( (output > 0.0) == (y > 0.5) ).float() ) # output is in logit space so threshold is 0.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X31sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39m# accuracies.append(accuracy.detach().cpu().numpy())\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X31sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mreturn\u001b[39;00m( np\u001b[39m.\u001b[39mmean(losses))\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 23,
      "block_group": "e7ce7ad511934f12a354a05cdc0a407f"
    },
    {
      "cell_type": "code",
      "source": "device = 'cuda'\noutputs = []\nexpected = []\ntransformer.eval()\n\nfor (x, y) in test_dataloader:  # iterate over batches\n    if torch.cuda.is_available():\n        y = y.to(device).float()\n        x = x.to(device).float()\n\n    output = transformer(x, y).squeeze()  # your awesome model here!\n\n    output_np = output.detach().cpu().numpy()\n    outputs.append(output_np)\n    # Move y to cpu before converting to numpy array\n    expected_np = y.cpu().numpy()  # Move to CPU for NumPy conversion\n    expected.append(expected_np)\n\n# Concatenate all the outputs and expected results\noutput_np = np.concatenate(outputs)\nexpected_np = np.concatenate(expected)\n\nprint(output_np)\nprint(expected_np)\n\n# Clip the values to be between 0 and 1\noutput_np = output_np.clip(0, 1)\nexpected_np = expected_np.clip(0, 1)\n\n# Calculate the Mean Absolute Error\nmae1 = np.mean(np.abs(output_np - expected_np))\nmae1\n",
      "metadata": {
        "cell_id": "473aef0b5a3c4d648b6ae6e58108804c",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "[[0.43928346 0.45013425 0.4399463  ... 0.44021487 0.45080703 0.44303825]\n [0.43928346 0.45013422 0.43994626 ... 0.44021487 0.45080703 0.44303823]\n [0.43928352 0.45013422 0.43994626 ... 0.44021484 0.4508071  0.44303828]\n ...\n [0.43928352 0.45013425 0.43994632 ... 0.44021487 0.4508071  0.4430383 ]\n [0.43928352 0.45013425 0.4399463  ... 0.44021487 0.45080703 0.44303825]\n [0.4392835  0.45013428 0.43994632 ... 0.44021484 0.4508071  0.44303828]]\n[[0.40836895 0.40836895 0.40836895 ... 0.40836895 0.40836895 0.40836895]\n [0.3389806  0.3389806  0.3389806  ... 0.3389806  0.3389806  0.3389806 ]\n [0.49919    0.49919    0.49919    ... 0.49919    0.49919    0.49919   ]\n ...\n [0.33333945 0.33333945 0.33333945 ... 0.33333945 0.33333945 0.33333945]\n [0.3354348  0.3354348  0.3354348  ... 0.3354348  0.3354348  0.3354348 ]\n [0.25894204 0.25894204 0.25894204 ... 0.25894204 0.25894204 0.25894204]]\n"
        },
        {
          "data": {
            "text/plain": "0.20098984"
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 24,
      "block_group": "bd7d36caaa0842d4a850206b435d7f38"
    },
    {
      "cell_type": "code",
      "source": "seqs, reactivities = df_toArray(X_DMS_train, y_DMS_train)\ntrain_dataset = BedPeaksDataset(seqs, reactivities)\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=100, num_workers = 0)\n\nseqs, reactivities = df_toArray(X_2A3_test, y_2A3_test)\ntest_dataset = BedPeaksDataset(seqs, reactivities)\ntest_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=100, num_workers = 0)",
      "metadata": {
        "cell_id": "e13b24b0881a4f41b12a154124d39e7f",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null,
      "block_group": "957b8293dedb414fbeec170413b12543"
    },
    {
      "cell_type": "code",
      "source": "import timeit\n# my_cnn1d_1 = CNN_1d()\n# print(my_cnn1d.seq_le\n# my_cnn1d_1 = my_cnn1d_1.float()\ntransformer = TransformerModel(input_dim= 5, d_model= 512, nhead= 8, num_encoder_layers = 2, dim_feedforward = 2048, n_output_channels = 206)\ntransformer, train_losses, test_losses = train_model(transformer, train_dataloader, test_dataloader, lr = 0.001, weight_decay = 0)",
      "metadata": {
        "cell_id": "46dbe6c4db7441d396b4af88a948936b",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "CUDA error: the launch timed out and was terminated\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32md:\\桌面\\xiaoyiass\\daima\\fork-of-rna-folding-transformer (1).ipynb 单元格 26\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X54sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# my_cnn1d_1 = CNN_1d()\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X54sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# print(my_cnn1d.seq_le\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X54sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# my_cnn1d_1 = my_cnn1d_1.float()\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X54sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m transformer \u001b[39m=\u001b[39m TransformerModel(input_dim\u001b[39m=\u001b[39m \u001b[39m5\u001b[39m, d_model\u001b[39m=\u001b[39m \u001b[39m512\u001b[39m, nhead\u001b[39m=\u001b[39m \u001b[39m8\u001b[39m, num_encoder_layers \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m, dim_feedforward \u001b[39m=\u001b[39m \u001b[39m2048\u001b[39m, n_output_channels \u001b[39m=\u001b[39m \u001b[39m206\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X54sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m transformer, train_losses, test_losses \u001b[39m=\u001b[39m train_model(transformer, train_dataloader, test_dataloader, lr \u001b[39m=\u001b[39;49m \u001b[39m0.001\u001b[39;49m, weight_decay \u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m)\n",
            "\u001b[1;32md:\\桌面\\xiaoyiass\\daima\\fork-of-rna-folding-transformer (1).ipynb 单元格 26\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X54sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# Move the model to the GPU here to make it runs there, and set \"device\" as above\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X54sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# TODO CODE\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X54sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X54sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     cnn_1d\u001b[39m.\u001b[39;49mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X54sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# 1. Make new BedPeakDataset and DataLoader objects for both training and validation data.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X54sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m# TODO CODE\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X54sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m#     train_dataset = BedPeaksDataset(train_data, genome, cnn_1d.seq_len)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X54sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m# 2. Instantiates an optimizer for the model.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X54sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m# TODO CODE\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X54sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(cnn_1d\u001b[39m.\u001b[39mparameters(), amsgrad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, lr \u001b[39m=\u001b[39m lr, weight_decay \u001b[39m=\u001b[39m weight_decay)\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m   1158\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m-> 1160\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[39mif\u001b[39;00m recurse:\n\u001b[0;32m    809\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 810\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    812\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    813\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    814\u001b[0m         \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    815\u001b[0m         \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    821\u001b[0m         \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    830\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    831\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    832\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 833\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    834\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    835\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1155\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[0;32m   1156\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m-> 1158\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: the launch timed out and was terminated\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "execution_count": null,
      "block_group": "1bf466b8a44e4f269e99342988d19529"
    },
    {
      "cell_type": "code",
      "source": "device = 'cuda'\noutputs = []\nexpected = []\ntransformer.eval()\n\nfor (x, y) in test_dataloader:  # iterate over batches\n    if torch.cuda.is_available():\n        y = y.to(device).float()\n        x = x.to(device).float()\n\n    output = transformer(x, y).squeeze()  # your awesome model here!\n    #output = torch.sigmoid(output)\n    output_np = output.detach().cpu().numpy()\n    outputs.append(output_np)\n    # Move y to cpu before converting to numpy array\n    expected_np = y.cpu().numpy()  # Move to CPU for NumPy conversion\n    expected.append(expected_np)\n\n# Concatenate all the outputs and expected results\noutput_np = np.concatenate(outputs)\nexpected_np = np.concatenate(expected)\n\nprint(output_np)\nprint(expected_np)\n\n# Clip the values to be between 0 and 1\noutput_np = output_np.clip(0, 1)\nexpected_np = expected_np.clip(0, 1)\n\n# Calculate the Mean Absolute Error\nmae1 = np.mean(np.abs(output_np - expected_np))\nmae1",
      "metadata": {
        "cell_id": "860c94878c474d118962c13f27e049c0",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null,
      "block_group": "f926e341564d4427aa4ff10427074e46"
    },
    {
      "cell_type": "code",
      "source": "# Training \ncriterion = F.mse_loss(output, y).float()\noptimizer = optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n\ntransformer.train()\n\nfor epoch in range(100):\n    optimizer.zero_grad()\n    output = transformer(src_data, tgt_data[:, :-1])\n    loss = criterion(output.contiguous().view(-1, tgt_vocab_size), tgt_data[:, 1:].contiguous().view(-1))\n    loss.backward()\n    optimizer.step()\n    print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")",
      "metadata": {
        "trusted": true,
        "cell_id": "3c180a39a1ff401ea6d3bc32383594d6",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'src_data' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32md:\\桌面\\xiaoyiass\\daima\\fork-of-rna-folding-transformer (1).ipynb 单元格 25\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X32sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X32sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X32sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     output \u001b[39m=\u001b[39m transformer(src_data, tgt_data[:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X32sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     loss \u001b[39m=\u001b[39m criterion(output\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, tgt_vocab_size), tgt_data[:, \u001b[39m1\u001b[39m:]\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/xiaoyiass/daima/fork-of-rna-folding-transformer%20%281%29.ipynb#X32sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
            "\u001b[1;31mNameError\u001b[0m: name 'src_data' is not defined"
          ]
        }
      ],
      "execution_count": null,
      "block_group": "ca8cb4c5c5c54f60b88d9ca611954f5d"
    },
    {
      "cell_type": "code",
      "source": "first_10_rows_ddf = dms_ddf.head(10)\nseqs1 = dms_ddf['sequence'].compute().tolist()\nseqs2 = twoa3_ddf['sequence'].compute().tolist()",
      "metadata": {
        "trusted": true,
        "cell_id": "74eb171328944c84afeda98351809d2d",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null,
      "block_group": "202a1daac7f4459db16fe79e54d074ae"
    },
    {
      "cell_type": "code",
      "source": "for i in range(len(seqs1)):\n    if len(seqs1[i])!= 170 or len(seqs1[i])!= 177:\n        print(len(seqs1[i]))",
      "metadata": {
        "trusted": true,
        "cell_id": "ca1663b4b4704097bf3d5d4fed2a5e64",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null,
      "block_group": "8af74c7a850e412b807f7fd3e572a54d"
    },
    {
      "cell_type": "markdown",
      "source": "The unigram, bigram, etc. may have different reactivity distributions for their nucleotides.\n\nLet's examine the reactivity distributions for the nucleotides of unigram, bigram, etc.",
      "metadata": {
        "cell_id": "e84208380c3b4decb919b801b52e6022",
        "deepnote_cell_type": "markdown"
      },
      "block_group": "42b3e85b731f45cbba0f2df284085f28"
    },
    {
      "cell_type": "code",
      "source": "# Given a row with a sequence and a subsequence,\n# returns a list of the reactivities of all\n# instances of the subsequence in the sequence\n# Example:\n#    getReactOfSubseqForRow(row, 'AUG') ->  [[-0.027, 0.429, 0.817], [-0.079, -0.014, 0.328]]\ndef getReactOfSubseqForRow(row, subseq):\n    \n    react = []\n    \n    for i in range(len(row['sequence']) - len(subseq)):\n        \n        if row['sequence'][i:i+len(subseq)] == subseq:\n            \n            react_curr = []\n            for j in range(i,i+len(subseq)):\n                react_curr.append(row['reactivity_' + f'{j+1:04}'])\n            \n            if not np.isnan(react_curr).any():\n                react.append(react_curr)\n    \n    return np.array(react)\n\n# Given a dataframe with sequences and a subsequence,\n# returns a dataframe of the reactivities of all\n# instances of the subsequence in the sequence\n# Example:\n#    getReactOfSubseqForRow(df, 'AUG') ->  \n#        ###############################\n#        # react_A # react_U # react_G #\n#        ###############################\n#        #   1.221 #   1.031 #   1.098 #\n#        #   1.272 #   1.453 #   1.007 #\n#        #   4.446 #   0.000 #   0.000 #\n#        ###############################\ndef getReactOfSubseqForFrame(df, subseq):\n    return df.apply(\n                getReactOfSubseqForRow,\n                subseq=subseq,\n                axis=1\n            ).explode().dropna().to_frame().apply(\n                lambda row: row[0],\n                axis=1,\n                result_type='expand'\n            ).rename(columns = {\n                i: f'react_{val}_{i}'\n                for i, val in enumerate(subseq)\n            })",
      "metadata": {
        "trusted": true,
        "cell_id": "5450f1ed7a8442eca5fa2f4e874b7911",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null,
      "block_group": "2260c2bc3a1642b6a040462577664534"
    },
    {
      "cell_type": "code",
      "source": "pdf_sn1 = shfl_ddf[shfl_ddf[\"SN_filter\"] == 1]\npdf_2a3 = pdf_sn1[pdf_sn1[\"experiment_type\"] == \"2A3_MaP\"].head(n=1000, compute=True)",
      "metadata": {
        "trusted": true,
        "cell_id": "8e7e803697bd44c6bc2c2bed161bba4e",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null,
      "block_group": "1632b29c1b8649b8b031727e01c2c37f"
    },
    {
      "cell_type": "code",
      "source": "for i in range(1, 3):\n    for subseq in product(\"AUGC\", repeat = i):\n        getReactOfSubseqForFrame(pdf_2a3, \"\".join(subseq)).hist(bins=20)\n        plt.show()\n        plt.close()",
      "metadata": {
        "trusted": true,
        "cell_id": "7f0eb5d9135448ae8a2e7771d10c7d6c",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null,
      "block_group": "264fe2358b57494a8da44502aaeadf1e"
    },
    {
      "cell_type": "markdown",
      "source": "The histograms tend to be right skewed and peak close to 0.",
      "metadata": {
        "cell_id": "80f2f2d76abe44438a88e56fbb21416e",
        "deepnote_cell_type": "markdown"
      },
      "block_group": "bc71c0a12ccf4681865cfe212bb6d2fa"
    },
    {
      "cell_type": "markdown",
      "source": "In the competition, the goal is not to predict reactivity, but reactivity (bounded), which is reactivity bounded between 0 and 1.\n\nLet's examine reactivity bounded.",
      "metadata": {
        "cell_id": "034431c5d1a248d1bdf5e5ed1b0c3e7d",
        "deepnote_cell_type": "markdown"
      },
      "block_group": "cf1865d254e24ea28b7bd191181301f4"
    },
    {
      "cell_type": "code",
      "source": "for i in range(1, 3):\n    for subseq in product(\"AUGC\", repeat = i):\n        getReactOfSubseqForFrame(pdf_2a3, \"\".join(subseq)).clip(0,1).hist(bins=20)\n        plt.show()\n        plt.close()",
      "metadata": {
        "trusted": true,
        "cell_id": "23c6326f6c0f41b2b264cd7fb552451d",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null,
      "block_group": "6b83812d12ae4415aec010893bf0a982"
    },
    {
      "cell_type": "markdown",
      "source": "The histograms often have 2 peaks, one at 0 and one at 1.",
      "metadata": {
        "cell_id": "ab2a15fadc01444c8256e6f03938288b",
        "deepnote_cell_type": "markdown"
      },
      "block_group": "510fd8204396436494a3456e569c3b20"
    },
    {
      "cell_type": "markdown",
      "source": "The histograms seem to be very similar across subsequences.\n\nLet's examine the distribution for subsequences of length 1. I am using a tool from [here](https://medium.com/the-researchers-guide/finding-the-best-distribution-that-fits-your-data-using-pythons-fitter-library-319a5a0972e9).",
      "metadata": {
        "cell_id": "a51fd1dd9340499f8d1bad3e9ac66c66",
        "deepnote_cell_type": "markdown"
      },
      "block_group": "0b90525ac9cd452995ec6722783eb720"
    },
    {
      "cell_type": "code",
      "source": "for b in \"AUGC\":\n    react = getReactOfSubseqForFrame(pdf_2a3, b).iloc[:, 0].values\n    f = Fitter(react)\n    f.fit(progress=True)\n    print(f.summary())\n    print(b)\n    plt.show()",
      "metadata": {
        "trusted": true,
        "cell_id": "a6036430f6534657931a6fd246aacd97",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null,
      "block_group": "086df12f1d784e19903ebebe70a9c360"
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=fe343e39-d2c0-4296-915d-091d9a42752d' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iODBweCIgaGVpZ2h0PSI4MHB4IiB2aWV3Qm94PSIwIDAgODAgODAiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDU0LjEgKDc2NDkwKSAtIGh0dHBzOi8vc2tldGNoYXBwLmNvbSAtLT4KICAgIDx0aXRsZT5Hcm91cCAzPC90aXRsZT4KICAgIDxkZXNjPkNyZWF0ZWQgd2l0aCBTa2V0Y2guPC9kZXNjPgogICAgPGcgaWQ9IkxhbmRpbmciIHN0cm9rZT0ibm9uZSIgc3Ryb2tlLXdpZHRoPSIxIiBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPgogICAgICAgIDxnIGlkPSJBcnRib2FyZCIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTEyMzUuMDAwMDAwLCAtNzkuMDAwMDAwKSI+CiAgICAgICAgICAgIDxnIGlkPSJHcm91cC0zIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxMjM1LjAwMDAwMCwgNzkuMDAwMDAwKSI+CiAgICAgICAgICAgICAgICA8cG9seWdvbiBpZD0iUGF0aC0yMCIgZmlsbD0iIzAyNjVCNCIgcG9pbnRzPSIyLjM3NjIzNzYyIDgwIDM4LjA0NzY2NjcgODAgNTcuODIxNzgyMiA3My44MDU3NTkyIDU3LjgyMTc4MjIgMzIuNzU5MjczOSAzOS4xNDAyMjc4IDMxLjY4MzE2ODMiPjwvcG9seWdvbj4KICAgICAgICAgICAgICAgIDxwYXRoIGQ9Ik0zNS4wMDc3MTgsODAgQzQyLjkwNjIwMDcsNzYuNDU0OTM1OCA0Ny41NjQ5MTY3LDcxLjU0MjI2NzEgNDguOTgzODY2LDY1LjI2MTk5MzkgQzUxLjExMjI4OTksNTUuODQxNTg0MiA0MS42NzcxNzk1LDQ5LjIxMjIyODQgMjUuNjIzOTg0Niw0OS4yMTIyMjg0IEMyNS40ODQ5Mjg5LDQ5LjEyNjg0NDggMjkuODI2MTI5Niw0My4yODM4MjQ4IDM4LjY0NzU4NjksMzEuNjgzMTY4MyBMNzIuODcxMjg3MSwzMi41NTQ0MjUgTDY1LjI4MDk3Myw2Ny42NzYzNDIxIEw1MS4xMTIyODk5LDc3LjM3NjE0NCBMMzUuMDA3NzE4LDgwIFoiIGlkPSJQYXRoLTIyIiBmaWxsPSIjMDAyODY4Ij48L3BhdGg+CiAgICAgICAgICAgICAgICA8cGF0aCBkPSJNMCwzNy43MzA0NDA1IEwyNy4xMTQ1MzcsMC4yNTcxMTE0MzYgQzYyLjM3MTUxMjMsLTEuOTkwNzE3MDEgODAsMTAuNTAwMzkyNyA4MCwzNy43MzA0NDA1IEM4MCw2NC45NjA0ODgyIDY0Ljc3NjUwMzgsNzkuMDUwMzQxNCAzNC4zMjk1MTEzLDgwIEM0Ny4wNTUzNDg5LDc3LjU2NzA4MDggNTMuNDE4MjY3Nyw3MC4zMTM2MTAzIDUzLjQxODI2NzcsNTguMjM5NTg4NSBDNTMuNDE4MjY3Nyw0MC4xMjg1NTU3IDM2LjMwMzk1NDQsMzcuNzMwNDQwNSAyNS4yMjc0MTcsMzcuNzMwNDQwNSBDMTcuODQzMDU4NiwzNy43MzA0NDA1IDkuNDMzOTE5NjYsMzcuNzMwNDQwNSAwLDM3LjczMDQ0MDUgWiIgaWQ9IlBhdGgtMTkiIGZpbGw9IiMzNzkzRUYiPjwvcGF0aD4KICAgICAgICAgICAgPC9nPgogICAgICAgIDwvZz4KICAgIDwvZz4KPC9zdmc+' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kaggle": {
      "language": "python",
      "sourceType": "notebook",
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 51294,
          "sourceType": "competition",
          "databundleVersionId": 6923401
        }
      ],
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "dockerImageVersionId": 30558
    },
    "deepnote": {},
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.3",
      "mimetype": "text/x-python",
      "file_extension": ".py",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "nbconvert_exporter": "python"
    },
    "deepnote_notebook_id": "531be543d0fb4126a13588541ff1f802",
    "deepnote_execution_queue": []
  }
}